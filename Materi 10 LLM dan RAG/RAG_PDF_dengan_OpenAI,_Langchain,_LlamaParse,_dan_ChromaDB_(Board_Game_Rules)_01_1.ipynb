{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Google Colab Link\n",
        "[Google Colab](https://colab.research.google.com/drive/1S3JW3iEBDCWLRL7wZkIHHvfJ4FfgOg99?usp=sharing)"
      ],
      "metadata": {
        "id": "jogCMqnxddKm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- https://youtu.be/u5Vcrwpzoz8?si=rxTbJQX87SHwf3Of"
      ],
      "metadata": {
        "id": "WN1z3sjULINs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clone Reference Repository"
      ],
      "metadata": {
        "id": "HZMJuAhOLGNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pixegami/rag-tutorial-v2\n",
        "!git clone https://github.com/pixegami/langchain-rag-tutorial.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_6XVlBdLIxn",
        "outputId": "22de4974-3b3f-4ff5-e348-e30e58939ff4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'rag-tutorial-v2'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 18 (delta 0), reused 10 (delta 0), pack-reused 3 (from 1)\u001b[K\n",
            "Receiving objects: 100% (18/18), 3.89 MiB | 7.71 MiB/s, done.\n",
            "Cloning into 'langchain-rag-tutorial'...\n",
            "remote: Enumerating objects: 41, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
            "remote: Total 41 (delta 9), reused 5 (delta 5), pack-reused 27 (from 1)\u001b[K\n",
            "Receiving objects: 100% (41/41), 78.44 KiB | 427.00 KiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Libraries"
      ],
      "metadata": {
        "id": "8DBVKobQLCt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary tools\n",
        "!sudo apt-get install -y pciutils\n",
        "# download ollama api\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "from IPython.display import clear_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBnqrFuNHv0V",
        "outputId": "c71acb29-293b-4e73-db78-e67c5574292c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "pciutils is already the newest version (1:3.7.0-6).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 CLI\n",
            "############################################################################################# 100.0%\n",
            ">>> Making ollama accessible in the PATH in /usr/local/bin\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            ">>> NVIDIA GPU installed.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama pull mistral\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "TEUNG9msIQJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ollama"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIBV5msqiqZy",
        "outputId": "949bb203-3a4d-4d34-a2a2-92c38d1cbf9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ollama in /usr/local/lib/python3.10/dist-packages (0.3.1)\n",
            "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from ollama) (0.27.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.4.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.8)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama) (1.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U llama-index --upgrade --no-cache-dir --force-reinstall\n",
        "!pip install llama-parse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8V9LuZY5O46G",
        "outputId": "ad1165f9-67cc-4c06-b609-6a04de67f188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index\n",
            "  Downloading llama_index-0.11.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting llama-index-agent-openai<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_agent_openai-0.3.0-py3-none-any.whl.metadata (728 bytes)\n",
            "Collecting llama-index-cli<0.4.0,>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_cli-0.3.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting llama-index-core<0.12.0,>=0.11.1 (from llama-index)\n",
            "  Downloading llama_index_core-0.11.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting llama-index-embeddings-openai<0.3.0,>=0.2.0 (from llama-index)\n",
            "  Downloading llama_index_embeddings_openai-0.2.3-py3-none-any.whl.metadata (635 bytes)\n",
            "Collecting llama-index-indices-managed-llama-cloud>=0.3.0 (from llama-index)\n",
            "  Downloading llama_index_indices_managed_llama_cloud-0.3.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
            "  Downloading llama_index_legacy-0.9.48.post3-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting llama-index-llms-openai<0.3.0,>=0.2.0 (from llama-index)\n",
            "  Downloading llama_index_llms_openai-0.2.0-py3-none-any.whl.metadata (648 bytes)\n",
            "Collecting llama-index-multi-modal-llms-openai<0.3.0,>=0.2.0 (from llama-index)\n",
            "  Downloading llama_index_multi_modal_llms_openai-0.2.0-py3-none-any.whl.metadata (728 bytes)\n",
            "Collecting llama-index-program-openai<0.3.0,>=0.2.0 (from llama-index)\n",
            "  Downloading llama_index_program_openai-0.2.0-py3-none-any.whl.metadata (766 bytes)\n",
            "Collecting llama-index-question-gen-openai<0.3.0,>=0.2.0 (from llama-index)\n",
            "  Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl.metadata (785 bytes)\n",
            "Collecting llama-index-readers-file<0.3.0,>=0.2.0 (from llama-index)\n",
            "  Downloading llama_index_readers_file-0.2.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting llama-index-readers-llama-parse>=0.2.0 (from llama-index)\n",
            "  Downloading llama_index_readers_llama_parse-0.2.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting nltk>3.8.1 (from llama-index)\n",
            "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.4.0,>=0.3.0->llama-index)\n",
            "  Downloading openai-1.42.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting PyYAML>=6.0.1 (from llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting SQLAlchemy>=1.4.49 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading SQLAlchemy-2.0.32-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Collecting aiohttp<4.0.0,>=3.8.6 (from llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading aiohttp-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
            "Collecting dataclasses-json (from llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting fsspec>=2023.5.0 (from llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting httpx (from llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting nest-asyncio<2.0.0,>=1.5.8 (from llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting networkx>=3.0 (from llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting numpy<2.0.0 (from llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow>=9.0.0 (from llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting pydantic<3.0.0,>=2.0.0 (from llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests>=2.31.0 (from llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.2.0 (from llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting tqdm<5.0.0,>=4.66.1 (from llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m241.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions>=4.5.0 (from llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting wrapt (from llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting llama-cloud>=0.0.11 (from llama-index-indices-managed-llama-cloud>=0.3.0->llama-index)\n",
            "  Downloading llama_cloud-0.0.15-py3-none-any.whl.metadata (751 bytes)\n",
            "Collecting pandas (from llama-index-legacy<0.10.0,>=0.9.48->llama-index)\n",
            "  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
            "Collecting beautifulsoup4<5.0.0,>=4.12.3 (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index)\n",
            "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index)\n",
            "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.3.0,>=0.2.0->llama-index)\n",
            "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse>=0.2.0->llama-index)\n",
            "  Downloading llama_parse-0.5.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting click (from nltk>3.8.1->llama-index)\n",
            "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting joblib (from nltk>3.8.1->llama-index)\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting regex>=2021.8.3 (from nltk>3.8.1->llama-index)\n",
            "  Downloading regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m223.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading aiohappyeyeballs-2.4.0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
            "Collecting async-timeout<5.0,>=4.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting soupsieve>1.2 (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.3.0,>=0.2.0->llama-index)\n",
            "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting anyio (from httpx->llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting certifi (from httpx->llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading certifi-2024.7.4-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting httpcore==1.* (from httpx->llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting idna (from httpx->llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading idna-3.8-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting sniffio (from httpx->llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting distro<2,>=1.7.0 (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.0->llama-index)\n",
            "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai>=1.14.0->llama-index-agent-openai<0.4.0,>=0.3.0->llama-index)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting annotated-types>=0.4.0 (from pydantic<3.0.0,>=2.0.0->llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.20.1 (from pydantic<3.0.0,>=2.0.0->llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading pydantic_core-2.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading urllib3-2.2.2-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting greenlet!=0.4.17 (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index)\n",
            "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index)\n",
            "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting exceptiongroup>=1.0.2 (from anyio->httpx->llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading exceptiongroup-1.2.2-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting packaging>=17.0 (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.1->llama-index)\n",
            "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas->llama-index-legacy<0.10.0,>=0.9.48->llama-index)\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Downloading llama_index-0.11.1-py3-none-any.whl (6.8 kB)\n",
            "Downloading llama_index_agent_openai-0.3.0-py3-none-any.whl (13 kB)\n",
            "Downloading llama_index_cli-0.3.0-py3-none-any.whl (27 kB)\n",
            "Downloading llama_index_core-0.11.1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_embeddings_openai-0.2.3-py3-none-any.whl (6.3 kB)\n",
            "Downloading llama_index_indices_managed_llama_cloud-0.3.0-py3-none-any.whl (9.5 kB)\n",
            "Downloading llama_index_legacy-0.9.48.post3-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m315.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_index_llms_openai-0.2.0-py3-none-any.whl (12 kB)\n",
            "Downloading llama_index_multi_modal_llms_openai-0.2.0-py3-none-any.whl (5.9 kB)\n",
            "Downloading llama_index_program_openai-0.2.0-py3-none-any.whl (5.3 kB)\n",
            "Downloading llama_index_question_gen_openai-0.2.0-py3-none-any.whl (2.9 kB)\n",
            "Downloading llama_index_readers_file-0.2.0-py3-none-any.whl (38 kB)\n",
            "Downloading llama_index_readers_llama_parse-0.2.0-py3-none-any.whl (2.5 kB)\n",
            "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m335.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohttp-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m328.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.9/147.9 kB\u001b[0m \u001b[31m301.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Downloading fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.6/177.6 kB\u001b[0m \u001b[31m304.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_cloud-0.0.15-py3-none-any.whl (180 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.2/180.2 kB\u001b[0m \u001b[31m315.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m149.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m232.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading llama_parse-0.5.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
            "Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m255.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m278.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.42.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.9/362.9 kB\u001b[0m \u001b[31m250.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m254.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.9/423.9 kB\u001b[0m \u001b[31m333.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m331.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m325.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.2/751.2 kB\u001b[0m \u001b[31m343.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading regex-2024.7.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (776 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.5/776.5 kB\u001b[0m \u001b[31m343.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m267.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading SQLAlchemy-2.0.32-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m334.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
            "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m351.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m287.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m288.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m290.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m318.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m315.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiohappyeyeballs-2.4.0-py3-none-any.whl (12 kB)\n",
            "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading anyio-4.4.0-py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m288.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
            "Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 kB\u001b[0m \u001b[31m267.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2024.7.4-py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.0/163.0 kB\u001b[0m \u001b[31m314.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.1/142.1 kB\u001b[0m \u001b[31m293.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m320.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.0/616.0 kB\u001b[0m \u001b[31m333.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.8-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 kB\u001b[0m \u001b[31m270.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m116.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m232.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m284.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m313.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m339.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
            "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m320.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.2.2-py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.4/121.4 kB\u001b[0m \u001b[31m314.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m326.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m265.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m261.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Installing collected packages: striprtf, pytz, dirtyjson, wrapt, urllib3, tzdata, typing-extensions, tqdm, tenacity, soupsieve, sniffio, six, regex, PyYAML, pillow, packaging, numpy, networkx, nest-asyncio, mypy-extensions, multidict, joblib, jiter, idna, h11, greenlet, fsspec, frozenlist, exceptiongroup, distro, click, charset-normalizer, certifi, attrs, async-timeout, annotated-types, aiohappyeyeballs, yarl, typing-inspect, SQLAlchemy, requests, python-dateutil, pypdf, pydantic-core, nltk, marshmallow, httpcore, deprecated, beautifulsoup4, anyio, aiosignal, tiktoken, pydantic, pandas, httpx, dataclasses-json, aiohttp, openai, llama-index-core, llama-cloud, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-legacy, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2024.1\n",
            "    Uninstalling pytz-2024.1:\n",
            "      Successfully uninstalled pytz-2024.1\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.16.0\n",
            "    Uninstalling wrapt-1.16.0:\n",
            "      Successfully uninstalled wrapt-1.16.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2024.1\n",
            "    Uninstalling tzdata-2024.1:\n",
            "      Successfully uninstalled tzdata-2024.1\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.5\n",
            "    Uninstalling tqdm-4.66.5:\n",
            "      Successfully uninstalled tqdm-4.66.5\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: soupsieve\n",
            "    Found existing installation: soupsieve 2.6\n",
            "    Uninstalling soupsieve-2.6:\n",
            "      Successfully uninstalled soupsieve-2.6\n",
            "  Attempting uninstall: sniffio\n",
            "    Found existing installation: sniffio 1.3.1\n",
            "    Uninstalling sniffio-1.3.1:\n",
            "      Successfully uninstalled sniffio-1.3.1\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.16.0\n",
            "    Uninstalling six-1.16.0:\n",
            "      Successfully uninstalled six-1.16.0\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2024.5.15\n",
            "    Uninstalling regex-2024.5.15:\n",
            "      Successfully uninstalled regex-2024.5.15\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.1\n",
            "    Uninstalling packaging-24.1:\n",
            "      Successfully uninstalled packaging-24.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.3\n",
            "    Uninstalling networkx-3.3:\n",
            "      Successfully uninstalled networkx-3.3\n",
            "  Attempting uninstall: nest-asyncio\n",
            "    Found existing installation: nest-asyncio 1.6.0\n",
            "    Uninstalling nest-asyncio-1.6.0:\n",
            "      Successfully uninstalled nest-asyncio-1.6.0\n",
            "  Attempting uninstall: multidict\n",
            "    Found existing installation: multidict 6.0.5\n",
            "    Uninstalling multidict-6.0.5:\n",
            "      Successfully uninstalled multidict-6.0.5\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.4.2\n",
            "    Uninstalling joblib-1.4.2:\n",
            "      Successfully uninstalled joblib-1.4.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.7\n",
            "    Uninstalling idna-3.7:\n",
            "      Successfully uninstalled idna-3.7\n",
            "  Attempting uninstall: h11\n",
            "    Found existing installation: h11 0.14.0\n",
            "    Uninstalling h11-0.14.0:\n",
            "      Successfully uninstalled h11-0.14.0\n",
            "  Attempting uninstall: greenlet\n",
            "    Found existing installation: greenlet 3.0.3\n",
            "    Uninstalling greenlet-3.0.3:\n",
            "      Successfully uninstalled greenlet-3.0.3\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.6.1\n",
            "    Uninstalling fsspec-2024.6.1:\n",
            "      Successfully uninstalled fsspec-2024.6.1\n",
            "  Attempting uninstall: frozenlist\n",
            "    Found existing installation: frozenlist 1.4.1\n",
            "    Uninstalling frozenlist-1.4.1:\n",
            "      Successfully uninstalled frozenlist-1.4.1\n",
            "  Attempting uninstall: exceptiongroup\n",
            "    Found existing installation: exceptiongroup 1.2.2\n",
            "    Uninstalling exceptiongroup-1.2.2:\n",
            "      Successfully uninstalled exceptiongroup-1.2.2\n",
            "  Attempting uninstall: distro\n",
            "    Found existing installation: distro 1.7.0\n",
            "    Uninstalling distro-1.7.0:\n",
            "      Successfully uninstalled distro-1.7.0\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.7\n",
            "    Uninstalling click-8.1.7:\n",
            "      Successfully uninstalled click-8.1.7\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.3.2\n",
            "    Uninstalling charset-normalizer-3.3.2:\n",
            "      Successfully uninstalled charset-normalizer-3.3.2\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2024.7.4\n",
            "    Uninstalling certifi-2024.7.4:\n",
            "      Successfully uninstalled certifi-2024.7.4\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 24.2.0\n",
            "    Uninstalling attrs-24.2.0:\n",
            "      Successfully uninstalled attrs-24.2.0\n",
            "  Attempting uninstall: async-timeout\n",
            "    Found existing installation: async-timeout 4.0.3\n",
            "    Uninstalling async-timeout-4.0.3:\n",
            "      Successfully uninstalled async-timeout-4.0.3\n",
            "  Attempting uninstall: annotated-types\n",
            "    Found existing installation: annotated-types 0.7.0\n",
            "    Uninstalling annotated-types-0.7.0:\n",
            "      Successfully uninstalled annotated-types-0.7.0\n",
            "  Attempting uninstall: aiohappyeyeballs\n",
            "    Found existing installation: aiohappyeyeballs 2.4.0\n",
            "    Uninstalling aiohappyeyeballs-2.4.0:\n",
            "      Successfully uninstalled aiohappyeyeballs-2.4.0\n",
            "  Attempting uninstall: yarl\n",
            "    Found existing installation: yarl 1.9.4\n",
            "    Uninstalling yarl-1.9.4:\n",
            "      Successfully uninstalled yarl-1.9.4\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.32\n",
            "    Uninstalling SQLAlchemy-2.0.32:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.32\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.20.1\n",
            "    Uninstalling pydantic_core-2.20.1:\n",
            "      Successfully uninstalled pydantic_core-2.20.1\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.8.1\n",
            "    Uninstalling nltk-3.8.1:\n",
            "      Successfully uninstalled nltk-3.8.1\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.5\n",
            "    Uninstalling httpcore-1.0.5:\n",
            "      Successfully uninstalled httpcore-1.0.5\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.12.3\n",
            "    Uninstalling beautifulsoup4-4.12.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.12.3\n",
            "  Attempting uninstall: anyio\n",
            "    Found existing installation: anyio 3.7.1\n",
            "    Uninstalling anyio-3.7.1:\n",
            "      Successfully uninstalled anyio-3.7.1\n",
            "  Attempting uninstall: aiosignal\n",
            "    Found existing installation: aiosignal 1.3.1\n",
            "    Uninstalling aiosignal-1.3.1:\n",
            "      Successfully uninstalled aiosignal-1.3.1\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.8.2\n",
            "    Uninstalling pydantic-2.8.2:\n",
            "      Successfully uninstalled pydantic-2.8.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.1.4\n",
            "    Uninstalling pandas-2.1.4:\n",
            "      Successfully uninstalled pandas-2.1.4\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.27.0\n",
            "    Uninstalling httpx-0.27.0:\n",
            "      Successfully uninstalled httpx-0.27.0\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.10.5\n",
            "    Uninstalling aiohttp-3.10.5:\n",
            "      Successfully uninstalled aiohttp-3.10.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.3.1+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "torch 2.3.1+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
            "xgboost 2.1.1 requires nvidia-nccl-cu12; platform_system == \"Linux\" and platform_machine != \"aarch64\", which is not installed.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 2.2.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.1.4, but you have pandas 2.2.2 which is incompatible.\n",
            "jupyter-server 1.24.0 requires anyio<4,>=3.1.0, but you have anyio 4.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyYAML-6.0.2 SQLAlchemy-2.0.32 aiohappyeyeballs-2.4.0 aiohttp-3.10.5 aiosignal-1.3.1 annotated-types-0.7.0 anyio-4.4.0 async-timeout-4.0.3 attrs-24.2.0 beautifulsoup4-4.12.3 certifi-2024.7.4 charset-normalizer-3.3.2 click-8.1.7 dataclasses-json-0.6.7 deprecated-1.2.14 dirtyjson-1.0.8 distro-1.9.0 exceptiongroup-1.2.2 frozenlist-1.4.1 fsspec-2024.6.1 greenlet-3.0.3 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 idna-3.8 jiter-0.5.0 joblib-1.4.2 llama-cloud-0.0.15 llama-index-0.11.1 llama-index-agent-openai-0.3.0 llama-index-cli-0.3.0 llama-index-core-0.11.1 llama-index-embeddings-openai-0.2.3 llama-index-indices-managed-llama-cloud-0.3.0 llama-index-legacy-0.9.48.post3 llama-index-llms-openai-0.2.0 llama-index-multi-modal-llms-openai-0.2.0 llama-index-program-openai-0.2.0 llama-index-question-gen-openai-0.2.0 llama-index-readers-file-0.2.0 llama-index-readers-llama-parse-0.2.0 llama-parse-0.5.0 marshmallow-3.22.0 multidict-6.0.5 mypy-extensions-1.0.0 nest-asyncio-1.6.0 networkx-3.3 nltk-3.9.1 numpy-1.26.4 openai-1.42.0 packaging-24.1 pandas-2.2.2 pillow-10.4.0 pydantic-2.8.2 pydantic-core-2.20.1 pypdf-4.3.1 python-dateutil-2.9.0.post0 pytz-2024.1 regex-2024.7.24 requests-2.32.3 six-1.16.0 sniffio-1.3.1 soupsieve-2.6 striprtf-0.0.26 tenacity-8.5.0 tiktoken-0.7.0 tqdm-4.66.5 typing-extensions-4.12.2 typing-inspect-0.9.0 tzdata-2024.1 urllib3-2.2.2 wrapt-1.16.0 yarl-1.9.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "certifi",
                  "dateutil",
                  "six"
                ]
              },
              "id": "a63b7768f5e542aab0f92418553e537e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-parse in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Requirement already satisfied: llama-index-core>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from llama-parse) (0.11.1)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core>=0.11.0->llama-parse) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (3.10.5)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (2024.6.1)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (0.27.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (3.3)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (3.9.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (1.26.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (10.4.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (2.8.2)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (0.7.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (4.12.2)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.11.0->llama-parse) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core>=0.11.0->llama-parse) (4.0.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core>=0.11.0->llama-parse) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core>=0.11.0->llama-parse) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core>=0.11.0->llama-parse) (2024.7.24)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->llama-index-core>=0.11.0->llama-parse) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.0.0->llama-index-core>=0.11.0->llama-parse) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-parse) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-parse) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-parse) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core>=0.11.0->llama-parse) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core>=0.11.0->llama-parse) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core>=0.11.0->llama-parse) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core>=0.11.0->llama-parse) (3.22.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core>=0.11.0->llama-parse) (4.4.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core>=0.11.0->llama-parse) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core>=0.11.0->llama-parse) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core>=0.11.0->llama-parse) (0.14.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core>=0.11.0->llama-parse) (24.1)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core>=0.11.0->llama-parse) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/langchain-rag-tutorial/requirements.txt\n",
        "!pip install -r /content/rag-tutorial-v2/requirements.txt\n",
        "!pip install \"unstructured[md]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V095t5y4Ld_n",
        "outputId": "1fbdd308-ffc4-4685-ce49-294ba45d107a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv==1.0.1 (from -r /content/langchain-rag-tutorial/requirements.txt (line 1))\n",
            "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting langchain==0.2.2 (from -r /content/langchain-rag-tutorial/requirements.txt (line 2))\n",
            "  Using cached langchain-0.2.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langchain-community==0.2.3 (from -r /content/langchain-rag-tutorial/requirements.txt (line 3))\n",
            "  Using cached langchain_community-0.2.3-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting langchain-openai==0.1.8 (from -r /content/langchain-rag-tutorial/requirements.txt (line 4))\n",
            "  Using cached langchain_openai-0.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting unstructured==0.14.4 (from -r /content/langchain-rag-tutorial/requirements.txt (line 5))\n",
            "  Using cached unstructured-0.14.4-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting chromadb==0.5.0 (from -r /content/langchain-rag-tutorial/requirements.txt (line 9))\n",
            "  Using cached chromadb-0.5.0-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting openai==1.31.1 (from -r /content/langchain-rag-tutorial/requirements.txt (line 10))\n",
            "  Using cached openai-1.31.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: tiktoken==0.7.0 in /usr/local/lib/python3.10/dist-packages (from -r /content/langchain-rag-tutorial/requirements.txt (line 11)) (0.7.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.2->-r /content/langchain-rag-tutorial/requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.2->-r /content/langchain-rag-tutorial/requirements.txt (line 2)) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.2->-r /content/langchain-rag-tutorial/requirements.txt (line 2)) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.2->-r /content/langchain-rag-tutorial/requirements.txt (line 2)) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.0 (from langchain==0.2.2->-r /content/langchain-rag-tutorial/requirements.txt (line 2))\n",
            "  Using cached langchain_core-0.2.35-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain==0.2.2->-r /content/langchain-rag-tutorial/requirements.txt (line 2))\n",
            "  Using cached langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.2.2->-r /content/langchain-rag-tutorial/requirements.txt (line 2))\n",
            "  Using cached langsmith-0.1.104-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.2->-r /content/langchain-rag-tutorial/requirements.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.2->-r /content/langchain-rag-tutorial/requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.2->-r /content/langchain-rag-tutorial/requirements.txt (line 2)) (2.32.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.2.2->-r /content/langchain-rag-tutorial/requirements.txt (line 2)) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community==0.2.3->-r /content/langchain-rag-tutorial/requirements.txt (line 3)) (0.6.7)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.4->-r /content/langchain-rag-tutorial/requirements.txt (line 5)) (5.2.0)\n",
            "Collecting filetype (from unstructured==0.14.4->-r /content/langchain-rag-tutorial/requirements.txt (line 5))\n",
            "  Using cached filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting python-magic (from unstructured==0.14.4->-r /content/langchain-rag-tutorial/requirements.txt (line 5))\n",
            "  Using cached python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.4->-r /content/langchain-rag-tutorial/requirements.txt (line 5)) (4.9.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.4->-r /content/langchain-rag-tutorial/requirements.txt (line 5)) (3.9.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.4->-r /content/langchain-rag-tutorial/requirements.txt (line 5)) (0.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.4->-r /content/langchain-rag-tutorial/requirements.txt (line 5)) (4.12.3)\n",
            "Collecting emoji (from unstructured==0.14.4->-r /content/langchain-rag-tutorial/requirements.txt (line 5))\n",
            "  Using cached emoji-2.12.1-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting python-iso639 (from unstructured==0.14.4->-r /content/langchain-rag-tutorial/requirements.txt (line 5))\n",
            "  Using cached python_iso639-2024.4.27-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langdetect (from unstructured==0.14.4->-r /content/langchain-rag-tutorial/requirements.txt (line 5))\n",
            "  Using cached langdetect-1.0.9.tar.gz (981 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting rapidfuzz (from unstructured==0.14.4->-r /content/langchain-rag-tutorial/requirements.txt (line 5))\n",
            "  Using cached rapidfuzz-3.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting backoff (from unstructured==0.14.4->-r /content/langchain-rag-tutorial/requirements.txt (line 5))\n",
            "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.4->-r /content/langchain-rag-tutorial/requirements.txt (line 5)) (4.12.2)\n",
            "Collecting unstructured-client (from unstructured==0.14.4->-r /content/langchain-rag-tutorial/requirements.txt (line 5))\n",
            "  Using cached unstructured_client-0.25.5-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured==0.14.4->-r /content/langchain-rag-tutorial/requirements.txt (line 5)) (1.16.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (1.2.1)\n",
            "Collecting chroma-hnswlib==0.7.3 (from chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9))\n",
            "  Using cached chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9))\n",
            "  Using cached fastapi-0.112.2-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9))\n",
            "  Using cached uvicorn-0.30.6-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting posthog>=2.4.0 (from chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9))\n",
            "  Using cached posthog-3.5.2-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9))\n",
            "  Using cached onnxruntime-1.19.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9))\n",
            "  Using cached opentelemetry_api-1.26.0-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9))\n",
            "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9))\n",
            "  Using cached opentelemetry_instrumentation_fastapi-0.47b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9))\n",
            "  Using cached opentelemetry_sdk-1.26.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (0.19.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9))\n",
            "  Using cached PyPika-0.48.9.tar.gz (67 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (4.66.5)\n",
            "Collecting overrides>=7.3.1 (from chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9))\n",
            "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (6.4.3)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (1.64.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9))\n",
            "  Using cached bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (0.12.4)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9))\n",
            "  Using cached kubernetes-30.1.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9))\n",
            "  Using cached mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting orjson>=3.9.12 (from chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9))\n",
            "  Using cached orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.31.1->-r /content/langchain-rag-tutorial/requirements.txt (line 10)) (4.4.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.31.1->-r /content/langchain-rag-tutorial/requirements.txt (line 10)) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.31.1->-r /content/langchain-rag-tutorial/requirements.txt (line 10)) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.31.1->-r /content/langchain-rag-tutorial/requirements.txt (line 10)) (1.3.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.7.0->-r /content/langchain-rag-tutorial/requirements.txt (line 11)) (2024.7.24)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.2->-r /content/langchain-rag-tutorial/requirements.txt (line 2)) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.2->-r /content/langchain-rag-tutorial/requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.2->-r /content/langchain-rag-tutorial/requirements.txt (line 2)) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.2->-r /content/langchain-rag-tutorial/requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.2->-r /content/langchain-rag-tutorial/requirements.txt (line 2)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.2->-r /content/langchain-rag-tutorial/requirements.txt (line 2)) (1.9.4)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.31.1->-r /content/langchain-rag-tutorial/requirements.txt (line 10)) (3.8)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.31.1->-r /content/langchain-rag-tutorial/requirements.txt (line 10)) (1.2.2)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (24.1)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (1.1.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (2.0.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.3->-r /content/langchain-rag-tutorial/requirements.txt (line 3)) (3.22.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.3->-r /content/langchain-rag-tutorial/requirements.txt (line 3)) (0.9.0)\n",
            "Collecting starlette<0.39.0,>=0.37.2 (from fastapi>=0.95.2->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9))\n",
            "  Downloading starlette-0.38.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.31.1->-r /content/langchain-rag-tutorial/requirements.txt (line 10)) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai==1.31.1->-r /content/langchain-rag-tutorial/requirements.txt (line 10)) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.31.1->-r /content/langchain-rag-tutorial/requirements.txt (line 10)) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (2.2.2)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.0->langchain==0.2.2->-r /content/langchain-rag-tutorial/requirements.txt (line 2))\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9))\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (1.13.2)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (1.2.14)\n",
            "Collecting importlib-metadata<=8.0.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9))\n",
            "  Downloading importlib_metadata-8.0.0-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (1.63.2)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9))\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.26.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9))\n",
            "  Downloading opentelemetry_proto-1.26.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9))\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.47b0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting opentelemetry-instrumentation==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9))\n",
            "  Downloading opentelemetry_instrumentation-0.47b0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9))\n",
            "  Downloading opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-util-http==0.47b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9))\n",
            "  Downloading opentelemetry_util_http-0.47b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (71.0.4)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9))\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9))\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.2.2->-r /content/langchain-rag-tutorial/requirements.txt (line 2)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain==0.2.2->-r /content/langchain-rag-tutorial/requirements.txt (line 2)) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.2.2->-r /content/langchain-rag-tutorial/requirements.txt (line 2)) (3.3.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.2.2->-r /content/langchain-rag-tutorial/requirements.txt (line 2)) (3.0.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (0.23.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (13.7.1)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9))\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9))\n",
            "  Downloading uvloop-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9))\n",
            "  Downloading watchfiles-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9))\n",
            "  Downloading websockets-13.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured==0.14.4->-r /content/langchain-rag-tutorial/requirements.txt (line 5)) (2.6)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured==0.14.4->-r /content/langchain-rag-tutorial/requirements.txt (line 5)) (1.4.2)\n",
            "Collecting deepdiff>=6.0 (from unstructured-client->unstructured==0.14.4->-r /content/langchain-rag-tutorial/requirements.txt (line 5))\n",
            "  Downloading deepdiff-7.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting jsonpath-python>=1.0.6 (from unstructured-client->unstructured==0.14.4->-r /content/langchain-rag-tutorial/requirements.txt (line 5))\n",
            "  Downloading jsonpath_python-1.0.6-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: mypy-extensions>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured==0.14.4->-r /content/langchain-rag-tutorial/requirements.txt (line 5)) (1.0.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured==0.14.4->-r /content/langchain-rag-tutorial/requirements.txt (line 5)) (1.6.0)\n",
            "Requirement already satisfied: pypdf>=4.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured==0.14.4->-r /content/langchain-rag-tutorial/requirements.txt (line 5)) (4.3.1)\n",
            "Collecting requests-toolbelt>=1.0.0 (from unstructured-client->unstructured==0.14.4->-r /content/langchain-rag-tutorial/requirements.txt (line 5))\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting ordered-set<4.2.0,>=4.1.0 (from deepdiff>=6.0->unstructured-client->unstructured==0.14.4->-r /content/langchain-rag-tutorial/requirements.txt (line 5))\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (2024.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.0.0,>=6.0->opentelemetry-api>=1.2.0->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (3.20.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain==0.2.2->-r /content/langchain-rag-tutorial/requirements.txt (line 2))\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (2.16.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.0->-r /content/langchain-rag-tutorial/requirements.txt (line 9)) (0.6.0)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading langchain-0.2.2-py3-none-any.whl (973 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.6/973.6 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.2.3-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.1.8-py3-none-any.whl (38 kB)\n",
            "Downloading unstructured-0.14.4-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-0.5.0-py3-none-any.whl (526 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.8/526.8 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.31.1-py3-none-any.whl (324 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m324.1/324.1 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl (273 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.112.2-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.5/93.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m82.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.2.35-py3-none-any.whl (394 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.9/394.9 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Downloading langsmith-0.1.104-py3-none-any.whl (149 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.1/149.1 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.19.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m111.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.26.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.26.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.26.0-py3-none-any.whl (17 kB)\n",
            "Downloading opentelemetry_proto-1.26.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.47b0-py3-none-any.whl (11 kB)\n",
            "Downloading opentelemetry_instrumentation-0.47b0-py3-none-any.whl (29 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.47b0-py3-none-any.whl (15 kB)\n",
            "Downloading opentelemetry_semantic_conventions-0.47b0-py3-none-any.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/138.0 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_util_http-0.47b0-py3-none-any.whl (6.9 kB)\n",
            "Downloading opentelemetry_sdk-1.26.0-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.5.2-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.5/41.5 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.30.6-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading emoji-2.12.1-py3-none-any.whl (431 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.4/431.4 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_iso639-2024.4.27-py3-none-any.whl (274 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.7/274.7 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Downloading rapidfuzz-3.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unstructured_client-0.25.5-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deepdiff-7.0.1-py3-none-any.whl (80 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.8/80.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-8.0.0-py3-none-any.whl (24 kB)\n",
            "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
            "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.38.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (427 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m427.7/427.7 kB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-13.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (157 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.2/157.2 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Building wheels for collected packages: pypika, langdetect\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53724 sha256=683263ea90c27079be204f70a364af93abdb26985206395681474367fec2e7cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993221 sha256=54d79542928753bd50dd2c35e32f58a89f3bca690a0cd9a393292d0959713f82\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built pypika langdetect\n",
            "Installing collected packages: pypika, monotonic, mmh3, filetype, websockets, uvloop, uvicorn, rapidfuzz, python-magic, python-iso639, python-dotenv, overrides, orjson, ordered-set, opentelemetry-util-http, opentelemetry-proto, langdetect, jsonpointer, jsonpath-python, importlib-metadata, humanfriendly, httptools, emoji, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, starlette, requests-toolbelt, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, jsonpatch, deepdiff, coloredlogs, unstructured-client, opentelemetry-semantic-conventions, opentelemetry-instrumentation, openai, onnxruntime, langsmith, kubernetes, fastapi, unstructured, opentelemetry-sdk, opentelemetry-instrumentation-asgi, langchain-core, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, langchain-text-splitters, langchain-openai, langchain, chromadb, langchain-community\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.4.0\n",
            "    Uninstalling importlib_metadata-8.4.0:\n",
            "      Successfully uninstalled importlib_metadata-8.4.0\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.42.0\n",
            "    Uninstalling openai-1.42.0:\n",
            "      Successfully uninstalled openai-1.42.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llama-index-llms-openai 0.2.0 requires openai<2.0.0,>=1.40.0, but you have openai 1.31.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.0 chroma-hnswlib-0.7.3 chromadb-0.5.0 coloredlogs-15.0.1 deepdiff-7.0.1 emoji-2.12.1 fastapi-0.112.2 filetype-1.2.0 httptools-0.6.1 humanfriendly-10.0 importlib-metadata-8.0.0 jsonpatch-1.33 jsonpath-python-1.0.6 jsonpointer-3.0.0 kubernetes-30.1.0 langchain-0.2.2 langchain-community-0.2.3 langchain-core-0.2.35 langchain-openai-0.1.8 langchain-text-splitters-0.2.2 langdetect-1.0.9 langsmith-0.1.104 mmh3-4.1.0 monotonic-1.6 onnxruntime-1.19.0 openai-1.31.1 opentelemetry-api-1.26.0 opentelemetry-exporter-otlp-proto-common-1.26.0 opentelemetry-exporter-otlp-proto-grpc-1.26.0 opentelemetry-instrumentation-0.47b0 opentelemetry-instrumentation-asgi-0.47b0 opentelemetry-instrumentation-fastapi-0.47b0 opentelemetry-proto-1.26.0 opentelemetry-sdk-1.26.0 opentelemetry-semantic-conventions-0.47b0 opentelemetry-util-http-0.47b0 ordered-set-4.1.0 orjson-3.10.7 overrides-7.7.0 posthog-3.5.2 pypika-0.48.9 python-dotenv-1.0.1 python-iso639-2024.4.27 python-magic-0.4.27 rapidfuzz-3.9.6 requests-toolbelt-1.0.0 starlette-0.38.2 unstructured-0.14.4 unstructured-client-0.25.5 uvicorn-0.30.6 uvloop-0.20.0 watchfiles-0.23.0 websockets-13.0\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (from -r /content/rag-tutorial-v2/requirements.txt (line 1)) (4.3.1)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (from -r /content/rag-tutorial-v2/requirements.txt (line 2)) (0.2.2)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (from -r /content/rag-tutorial-v2/requirements.txt (line 3)) (0.5.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from -r /content/rag-tutorial-v2/requirements.txt (line 4)) (7.4.4)\n",
            "Collecting boto3 (from -r /content/rag-tutorial-v2/requirements.txt (line 5))\n",
            "  Using cached boto3-1.35.5-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf->-r /content/rag-tutorial-v2/requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/rag-tutorial-v2/requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/rag-tutorial-v2/requirements.txt (line 2)) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/rag-tutorial-v2/requirements.txt (line 2)) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/rag-tutorial-v2/requirements.txt (line 2)) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/rag-tutorial-v2/requirements.txt (line 2)) (0.2.35)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/rag-tutorial-v2/requirements.txt (line 2)) (0.2.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/rag-tutorial-v2/requirements.txt (line 2)) (0.1.104)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/rag-tutorial-v2/requirements.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/rag-tutorial-v2/requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/rag-tutorial-v2/requirements.txt (line 2)) (2.32.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain->-r /content/rag-tutorial-v2/requirements.txt (line 2)) (8.5.0)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (1.2.1)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.3 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (0.7.3)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (0.112.2)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (0.30.6)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (3.5.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (1.19.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (1.26.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (1.26.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (0.47b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (1.26.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (0.19.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (4.66.5)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (6.4.3)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (1.64.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (4.2.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (0.12.4)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (30.1.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (4.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (3.10.7)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->-r /content/rag-tutorial-v2/requirements.txt (line 4)) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest->-r /content/rag-tutorial-v2/requirements.txt (line 4)) (24.1)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->-r /content/rag-tutorial-v2/requirements.txt (line 4)) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->-r /content/rag-tutorial-v2/requirements.txt (line 4)) (1.2.2)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->-r /content/rag-tutorial-v2/requirements.txt (line 4)) (2.0.1)\n",
            "Collecting botocore<1.36.0,>=1.35.5 (from boto3->-r /content/rag-tutorial-v2/requirements.txt (line 5))\n",
            "  Downloading botocore-1.35.5-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->-r /content/rag-tutorial-v2/requirements.txt (line 5))\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->-r /content/rag-tutorial-v2/requirements.txt (line 5))\n",
            "  Downloading s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r /content/rag-tutorial-v2/requirements.txt (line 2)) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r /content/rag-tutorial-v2/requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r /content/rag-tutorial-v2/requirements.txt (line 2)) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r /content/rag-tutorial-v2/requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r /content/rag-tutorial-v2/requirements.txt (line 2)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r /content/rag-tutorial-v2/requirements.txt (line 2)) (1.9.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.5->boto3->-r /content/rag-tutorial-v2/requirements.txt (line 5)) (2.9.0.post0)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.36.0,>=1.35.5->boto3->-r /content/rag-tutorial-v2/requirements.txt (line 5)) (2.2.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (0.38.2)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (2024.7.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (3.2.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain->-r /content/rag-tutorial-v2/requirements.txt (line 2)) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain->-r /content/rag-tutorial-v2/requirements.txt (line 2)) (0.27.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (1.13.2)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<=8.0.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (8.0.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (1.63.2)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.26.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (1.26.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.26.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (1.26.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.47b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (0.47b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.47b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (0.47b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.47b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (0.47b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.47b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (0.47b0)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (71.0.4)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.47b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain->-r /content/rag-tutorial-v2/requirements.txt (line 2)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain->-r /content/rag-tutorial-v2/requirements.txt (line 2)) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain->-r /content/rag-tutorial-v2/requirements.txt (line 2)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain->-r /content/rag-tutorial-v2/requirements.txt (line 2)) (3.8)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain->-r /content/rag-tutorial-v2/requirements.txt (line 2)) (3.0.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (0.23.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (13.7.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (0.20.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (0.23.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (13.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (4.9)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain->-r /content/rag-tutorial-v2/requirements.txt (line 2)) (4.4.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain->-r /content/rag-tutorial-v2/requirements.txt (line 2)) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain->-r /content/rag-tutorial-v2/requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (2024.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.0.0,>=6.0->opentelemetry-api>=1.2.0->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (3.20.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain->-r /content/rag-tutorial-v2/requirements.txt (line 2)) (3.0.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (2.16.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r /content/rag-tutorial-v2/requirements.txt (line 3)) (0.6.0)\n",
            "Downloading boto3-1.35.5-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.35.5-py3-none-any.whl (12.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m84.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jmespath, botocore, s3transfer, boto3\n",
            "Successfully installed boto3-1.35.5 botocore-1.35.5 jmespath-1.0.1 s3transfer-0.10.2\n",
            "Requirement already satisfied: unstructured[md] in /usr/local/lib/python3.10/dist-packages (0.14.4)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured[md]) (5.2.0)\n",
            "Requirement already satisfied: filetype in /usr/local/lib/python3.10/dist-packages (from unstructured[md]) (1.2.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from unstructured[md]) (0.4.27)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured[md]) (4.9.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured[md]) (3.9.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured[md]) (0.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from unstructured[md]) (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured[md]) (4.12.3)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from unstructured[md]) (2.12.1)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from unstructured[md]) (0.6.7)\n",
            "Requirement already satisfied: python-iso639 in /usr/local/lib/python3.10/dist-packages (from unstructured[md]) (2024.4.27)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (from unstructured[md]) (1.0.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unstructured[md]) (1.26.4)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from unstructured[md]) (3.9.6)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (from unstructured[md]) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from unstructured[md]) (4.12.2)\n",
            "Requirement already satisfied: unstructured-client in /usr/local/lib/python3.10/dist-packages (from unstructured[md]) (0.25.5)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured[md]) (1.16.0)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from unstructured[md]) (3.7)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured[md]) (2.6)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured[md]) (3.22.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->unstructured[md]) (0.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect->unstructured[md]) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[md]) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[md]) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[md]) (2024.7.24)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[md]) (4.66.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured[md]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured[md]) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured[md]) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->unstructured[md]) (2024.7.4)\n",
            "Requirement already satisfied: deepdiff>=6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[md]) (7.0.1)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[md]) (0.27.0)\n",
            "Requirement already satisfied: jsonpath-python>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[md]) (1.0.6)\n",
            "Requirement already satisfied: mypy-extensions>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[md]) (1.0.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[md]) (1.6.0)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[md]) (24.1)\n",
            "Requirement already satisfied: pypdf>=4.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[md]) (4.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[md]) (2.9.0.post0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[md]) (1.0.0)\n",
            "Requirement already satisfied: ordered-set<4.2.0,>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from deepdiff>=6.0->unstructured-client->unstructured[md]) (4.1.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured[md]) (4.4.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured[md]) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->unstructured-client->unstructured[md]) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->unstructured-client->unstructured[md]) (0.14.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->unstructured-client->unstructured[md]) (1.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Ollama Server"
      ],
      "metadata": {
        "id": "nf6V5RI33uYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Python script to start the Ollama API server in a separate thread\n",
        "import os\n",
        "import threading\n",
        "import subprocess\n",
        "import requests\n",
        "import json\n",
        "\n",
        "def ollama():\n",
        "    os.environ['OLLAMA_HOST'] = '0.0.0.0:11434'\n",
        "    os.environ['OLLAMA_ORIGINS'] = '*'\n",
        "    subprocess.Popen([\"ollama\", \"serve\"])\n",
        "\n",
        "ollama_thread = threading.Thread(target=ollama)\n",
        "ollama_thread.start()"
      ],
      "metadata": {
        "id": "_0saGKbH3wHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parse PDF as Markdowns using Llama Parse"
      ],
      "metadata": {
        "id": "yzp1p3TiQQ9r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "ODsPDi4HQe1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os"
      ],
      "metadata": {
        "id": "DBRT9kAxQZys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Paths"
      ],
      "metadata": {
        "id": "S0DHFF9JQeW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CHROMA_PATH = \"chroma\"\n",
        "DATA_PATH = \"/content/rag-tutorial-v2/data\""
      ],
      "metadata": {
        "id": "oWUhAyrJQc09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the URL and the path\n",
        "url = \"https://czechgames.com/files/rules/codenames-rules-en.pdf\"\n",
        "save_path = DATA_PATH + \"/codenames-rules-en.pdf\"\n",
        "\n",
        "# Ensure the directory exists\n",
        "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "\n",
        "# Download the file\n",
        "response = requests.get(url)\n",
        "\n",
        "# Save the file\n",
        "with open(save_path, 'wb') as file:\n",
        "    file.write(response.content)"
      ],
      "metadata": {
        "id": "o4uTjnn1QalV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/content/rag-tutorial-v2/data/md', exist_ok=True)"
      ],
      "metadata": {
        "id": "HbPwFO9HQwS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Parsing"
      ],
      "metadata": {
        "id": "wrsuQgqFf4jk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['LLAMA_CLOUD_API_KEY'] = 'llx-c718iy1gIgqFjHhK5hKjVMStcCaCM4pDzaF4ojH15V9ylJAK'"
      ],
      "metadata": {
        "id": "gAgX_2lGgNeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "XdRRnkLQgIOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_parse import LlamaParse\n",
        "parser = LlamaParse(\n",
        "    result_type=\"markdown\",\n",
        "    num_workers=4,\n",
        "    verbose=True,\n",
        "    language=\"en\",\n",
        ")"
      ],
      "metadata": {
        "id": "BcOkJUDbhC_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory containing PDF files\n",
        "pdf_directory = '/content/rag-tutorial-v2/data/'\n",
        "# Directory to store markdown files\n",
        "markdown_directory = '/content/rag-tutorial-v2/data/md/'\n",
        "\n",
        "# Create markdown directory if it doesn't exist\n",
        "if not os.path.exists(markdown_directory):\n",
        "    os.makedirs(markdown_directory)\n",
        "\n",
        "# List all PDF files in the directory\n",
        "pdf_files = [f for f in os.listdir(pdf_directory) if f.endswith('.pdf')]\n",
        "\n",
        "# Process each PDF file\n",
        "for pdf_file in pdf_files:\n",
        "    # Load the PDF data\n",
        "    documents = await parser.aload_data(os.path.join(pdf_directory, pdf_file))\n",
        "\n",
        "    # Determine the number of indexes\n",
        "    num_indexes = len(documents)\n",
        "    print(f\"The document '{pdf_file}' has {num_indexes} indexes.\")\n",
        "\n",
        "    # Write all document contents to a markdown file in the new directory\n",
        "    markdown_file = os.path.join(markdown_directory, pdf_file.replace('.pdf', '.md'))\n",
        "    with open(markdown_file, \"w\") as f:\n",
        "        for i in range(num_indexes):\n",
        "            f.write(documents[i].text)\n",
        "            f.write(\"\\n\\n\")  # Add a newline between documents for separation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "CvwlsKe_Hd25",
        "outputId": "4741a2e6-8b5c-4587-861e-4d4324868dcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started parsing the file under job_id dd709dd8-3f61-4d96-a0d8-3f0aa2c582e5\n",
            "The document 'codenames-rules-en.pdf' has 8 indexes.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_92a065a6-a4e3-461d-be10-71f7da1703bc\", \"codenames-rules-en.md\", 16754)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started parsing the file under job_id 5f2c6d53-b7ea-4c93-8bf8-1b0742f89d92\n",
            "The document 'ticket_to_ride.pdf' has 4 indexes.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0006390d-5b45-4158-8bed-458740899102\", \"ticket_to_ride.md\", 11408)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Started parsing the file under job_id f5c34b7a-fd0f-4dcb-a117-2c5184160a1c\n",
            "The document 'monopoly.pdf' has 8 indexes.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_07b14274-a7a0-4ae5-a9ae-76721236dc7a\", \"monopoly.md\", 15758)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Markdown Documents\n",
        "- https://python.langchain.com/v0.1/docs/modules/data_connection/document_loaders/"
      ],
      "metadata": {
        "id": "kYvv295CYmoy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Paths"
      ],
      "metadata": {
        "id": "7QHkYqUWfYQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import os"
      ],
      "metadata": {
        "id": "KV078lIw9P5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_PATH = \"/content/rag-tutorial-v2/data/md\""
      ],
      "metadata": {
        "id": "bjbumeWkfblb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define and Call Function"
      ],
      "metadata": {
        "id": "yuGZFjCKgMQy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import UnstructuredMarkdownLoader\n",
        "\n",
        "def load_documents():\n",
        "    \"\"\"\n",
        "    Purpose/Usage: Loads markdown documents from a specified directory.\n",
        "    Inputs: None\n",
        "    Outputs/Returns: A list of Document objects loaded from the specified directory.\n",
        "    \"\"\"\n",
        "    documents = []\n",
        "    for filename in os.listdir(DATA_PATH):\n",
        "        if filename.endswith('.md'):\n",
        "            file_path = os.path.join(DATA_PATH, filename)\n",
        "            loader = UnstructuredMarkdownLoader(file_path)\n",
        "            documents.extend(loader.load())\n",
        "    return documents"
      ],
      "metadata": {
        "id": "sXlycFy1YoVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each document contains the text content of the PDF along with some metadata attached"
      ],
      "metadata": {
        "id": "553ZqCYCfzoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vp_vWHE5Jayq",
        "outputId": "4ac23fda-09b1-4e74-fcea-89eee73b7747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print an example document\n",
        "documents = load_documents( )\n",
        "print(documents[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQlMiif7fpw8",
        "outputId": "69a93371-6b72-4f40-a3c1-3315038c19a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='MONOPOLY\n",
            "\n",
            "Property Trading Game from Parker Brothers\n",
            "\n",
            "AGES 8+\n",
            "\n",
            "2 to 8 Players\n",
            "\n",
            "Contents: Gameboard, 3 dice, tokens, 32 houses, 12 hotels, Chance and Community Chest cards, Title Deed cards, play money and a Banker's tray.\n",
            "\n",
            "Now there's a faster way to play MONOPOLY. Choose to play by the classic rules for buying, renting and selling properties or use the Speed Die to get into the action faster. If you've never played the classic MONOPOLY game, refer to the Classic Rules beginning on the next page. If you already know how to play and want to use the Speed Die, just read the section below for the additional Speed Die rules.\n",
            "\n",
            "SPEED DIE RULES\n",
            "\n",
            "Learning how to Play with the Speed Die is as fast as playing with it.\n",
            "\n",
            "When starting the game, hand out an extra $1,000 to each player (two $500s should work). The game moves fast and you'll need the extra cash to buy and build.\n",
            "\n",
            "Do not use the Speed Die until you've landed on or passed over GO for the first time. Once you collect that first $200 salary, you'll use the Speed Die for the rest of the game. This means that some players will start using the die before others.\n",
            "\n",
            "Once you start using the Speed Die, roll it along with the two white dice on your turn. Then do the following depending on what you rolled.\n",
            "\n",
            "1, 2, or 3: Add this number to the roll of the two white dice. You'll zoom around the board.\n",
            "\n",
            "Bus:\n",
            "\n",
            "This lets you \"get off the bus early.\" Look at the two white dice. You can move the value of one die, the other die, or the sum of both dice. So if you rolled a 1 and a 5, you can move 1 space, 5 spaces, or 6 spaces: it's your choice.\n",
            "\n",
            "Mr. Monopoly:\n",
            "\n",
            "First, move the sum of the two white dice and resolve the space you land on (such as drawing a card, buying the property, paying rent, etc.). Then, one of two things will happen depending on whether or not there is still property in the bank.\n",
            "\n",
            "YES, there is property in the bank - Advance to the next property that the bank still holds and buy it if you wish. If you don't want to buy this property, move to the space anyway and put the property up for auction.\n",
            "\n",
            "NO, there are no more properties in the bank - Advance to the next property on which you will owe another player money.\n",
            "\n",
            "A few minor details:\n",
            "\n",
            "Only the white dice are used when determining if you rolled doubles.\n",
            "\n",
            "Do not look at the Speed Die.\n",
            "\n",
            "If you roll a three-of-a-kind (all of the dice show the same number), you can move anywhere you want on the board!\n",
            "\n",
            "If you get sent to jail during your move (either by landing on the \"Go to Jail\" space or by rolling doubles three times in a row) then your turn is over and you do not get to use the Speed Die for that turn.\n",
            "\n",
            "Use the white dice ONLY when rolling to get out of jail.\n",
            "\n",
            "Use the sum of all three dice when determining how much to pay on a utility. Note: The Bus and Mr. Monopoly are valued at 0.\n",
            "\n",
            "Classic Monopoly Rules\n",
            "\n",
            "OBJECT: The object of the game is to become the wealthiest player through buying, renting and selling property.\n",
            "\n",
            "PREPARATION: Place the board on a table and put the Chance and Community Chest cards facedown on their allotted spaces on the board. Each player chooses one token to represent him/her while traveling around the board.\n",
            "\n",
            "Each player is given $1,500 divided as follows: andP each of $500s, $100 and $50; 6 $40; 5 each of $10, $5 and $1. All remaining money and other equipment go to the Bank. Stack the Bank's money on edge in the compartments in the plastic Banker's tray.\n",
            "\n",
            "BANKER. Select as Banker a player who will also make a good Auctioneer. A Banker who plays in the game must keep his/her personal funds separate from those of the Bank. When more than five persons play, the Banker may elect to act only as Banker and Auctioneer.\n",
            "\n",
            "THE BANK: Besides the Bank's money, the Bank holds the Title Deed cards and houses and hotels prior to purchase and use by the players. The Bank pays salaries and bonuses. It sells and auctions properties and hands out their proper Title Deed cards; it sells houses and hotels to the players and loans money when required on mortgages. The Bank collects all taxes, fines, loans and interest, and the price of all properties which it sells and auctions. The Bank never \"goes broke.\" If the Bank runs out of money, the Banker may issue as much more as needed by writing on any ordinary paper.\n",
            "\n",
            "THE PLAY: Starting with the Banker, each player in turn throws the dice. The player with the highest total starts the play: Place your token on the corner marked \"GO,\" throw the dice and move your token in the direction of the arrow the number of spaces indicated by the dice. After you have completed your play, the turn passes to the left. The tokens remain on the spaces occupied and proceed from that point on the player's next turn. Two or more tokens may rest on the same space at the same time. According to the space your token reaches, you may be entitled to buy real estate or other properties - or obliged to pay rent, pay taxes, draw a Chance or Community Chest card, \"Go to Jail,\" etc. If you throw doubles, you move your token as usual, the sum of the two dice, and are subject to any privileges or penalties pertaining to the space on which you land. Retaining the dice, throw again and move your token as before. If you throw doubles three times in succession, move your token immediately to the space marked \"In Jail\" (see JAIL).\n",
            "\n",
            "GO\n",
            "\n",
            "Each time a player's token lands on or passes over GO, whether by throwing the dice or drawing a card, the Banker pays him/her a $200 salary.\n",
            "\n",
            "The $200 is paid only once each time around the board. However, if a player passing GO on the throw of the dice lands 2 spaces beyond it on Community Chest, or 7 spaces beyond it on Chance, and draws the \"Advance to GO\" card, he/she collects $200 for passing GO the first time and another $200 for reaching it the second time by instructions on the card.\n",
            "\n",
            "BUYING PROPERTY\n",
            "\n",
            "Whenever you land on an unowned property you may buy that property from the Bank at its printed price. You receive the Title Deed card showing ownership; place it faceup in front of you.\n",
            "\n",
            "If you do not wish to buy the property, the Banker sells it at auction to the highest bidder. The buyer pays the Bank the amount of the bid in cash and receives the Title Deed card for that property. Any player, including the one who declined the option to buy it at the printed price, may bid. Bidding may start at any price.\n",
            "\n",
            "PAYING RENT\n",
            "\n",
            "When you land on property owned by another player, the owner collects rent from you in accordance with the list printed on its Title Deed card.\n",
            "\n",
            "If the property is mortgaged, no rent can be collected. When a property is mortgaged, its Title Deed card is placed facedown in front of the owner.\n",
            "\n",
            "It is an advantage to hold all the Title Deed cards in a color-group (e.g., Boardwalk and Park Place; or Connecticut, Vermont and Oriental Avenues) because the owner may then charge double rent for unimproved properties in that color-group. This rule applies to unmortgaged properties even if another property in that color-group is mortgaged.\n",
            "\n",
            "It is even more advantageous to have houses or hotels on properties because rents are much higher than for unimproved properties.\n",
            "\n",
            "The owner may not collect the rent if he/she fails to ask for it before the second player following throws the dice.\n",
            "\n",
            "CHANCE AND COMMUNITY CHEST\n",
            "\n",
            "When you land on either of these spaces, take the top card from the deck indicated, follow the instructions on the card.\n",
            "\n",
            "instructions and return the card facedown to the bottom of the deck. The \"Get Out of Jail Free\" card is held until used and then returned to the bottom of the deck. If the player who draws it does not wish to use it, he/she may sell it, at any time, to another player at a price agreeable to both.\n",
            "\n",
            "If you land here you have two options: You may \"INCOME TAX\" at $900 and pay the Bank, or you may pay 10% of your total worth to the Bank. Your total worth is all your cash on hand, printed prices of mortgaged and unmortgaged properties and cost price of all buildings you own. You must decide which option you will take before you add up your total worth.\n",
            "\n",
            "\"JAIL\": You land in Jail when: (1) your token lands on the space \"Go to Jail\"; (2) you draw a card marked \"Go to Jail\"; or (3) you throw doubles three times in succession. When you are sent to Jail you cannot collect your $200 salary in that move since, regardless of where your token is on the board, you must move it directly into Jail. Your turn ends when you are sent to Jail. If you are not \"sent\" to Jail but in the ordinary course of play land on that space, you are \"Just Visiting,\" you incur no penalty, and you move ahead in the usual manner on your next turn.\n",
            "\n",
            "You get out of Jail by: (1) throwing doubles on any of your next three turns; if you succeed in doing this you immediately move forward the number of spaces shown by your doubles throw; even though you had thrown doubles, you do not take another turn; (2) using the \"Get Out of Jail Free\" card if you have it; (3) purchasing the \"Get Out of Jail Free\" card from another player and playing it; (4) paying a fine of $50 before you roll the dice on either of your next two turns. If you do not throw doubles by your third turn, you must pay the $50 fine. You then get out of Jail and immediately move forward the number of spaces shown by your throw. Even though you are in Jail, you may buy and sell property, buy and sell houses and hotels and collect rents.\n",
            "\n",
            "FREE PARKING: A player landing on this place does not receive any money, property or reward of any kind. This is a \"free\" resting place.\n",
            "\n",
            "HOUSES: When you own all the properties in a color-group you may buy houses from the Bank and erect them on those properties.\n",
            "\n",
            "If you buy one house, you may put it on any one of those properties. The next house you buy must be erected on one of the unimproved properties of this or any other complete color-group you may own.\n",
            "\n",
            "The price you must pay the Bank for each house is shown on your title Deed card for the property on which you erect the house.\n",
            "\n",
            "The owner still collects double rent from an opponent who lands on the unimproved properties of his/her complete color-group.\n",
            "\n",
            "Following the above rules, you may buy and erect at any time as many houses as your judgment and financial standing will allow. But you must build evenly, i.e., you cannot erect more than one house on any one property of any color-group until you have built one house on every property of that group. You may then begin on the second row of houses, and so on, up to a limit of four houses to a property. For example, you cannot build three houses on one property if you have only one house on another property of that group.\n",
            "\n",
            "As you build evenly, you must also break down evenly if you sell houses back to the Bank (see SELLING PROPERTY).\n",
            "\n",
            "HOTELS: When a player has four houses on each property of a complete color-group, he/she may buy a hotel from the Bank and erect it on any property of the color-group. He/she returns the four houses from that property to the Bank and pays the price for the hotel as shown on the Title Deed card. Only one hotel may be erected on any one property.\n",
            "\n",
            "BUILDING SHORTAGES: When the Bank has no houses to sell, players wishing to build must wait for some player to return or sell his/her houses to the Bank before building. If there are a limited number of houses and hotels available and two or more players wish to buy more than the Bank has, the houses or hotels must be sold at auction to the highest bidder.\n",
            "\n",
            "SELLING PROPERTY: Unimproved properties, railroads, and utilities (but not buildings) may be sold to any player as a private transaction for any amount the owner can get; however, no property can be sold to another player if buildings are standing on any properties of that color-group. Any buildings so located must be sold back to the Bank before the owner can sell any property of that color-group.\n",
            "\n",
            "Houses and hotels may be sold back to the Bank at any time for one-half the price paid for them.\n",
            "\n",
            "All houses on one color-group must be sold one by one, evenly, in reverse of the manner in which they were erected.\n",
            "\n",
            "All hotels on one color-group may be sold at once, or they may be sold one house at a time (one hotel equals five houses), evenly, in reverse of the manner in which they were erected.\n",
            "\n",
            "MORTGAGES: Unimproved properties can be mortgaged through the Bank at any time. Before an improved property can be mortgaged, all the buildings on all the properties of its color-group must be sold back to the Bank at half price. The mortgage value is printed on each Title Deed card.\n",
            "\n",
            "No rent can be collected on mortgaged properties or utilities, but rent can be collected on unmortgaged properties in the same group.\n",
            "\n",
            "In order to lift the mortgage, the owner must pay the Bank the amount of the mortgage plus 10% interest. When all the properties of a color-group are no longer mortgaged, the owner may begin to buy back houses at full price.\n",
            "\n",
            "The player who mortgages property retains possession of it and no other player may secure it by lifting the mortgage from the Bank. However, the owner may sell this mortgaged property to another player at any agreed price. If you are the new owner, you may lift the mortgage at once if you wish by paying off the mortgage plus 10% interest to the Bank. If the mortgage is not lifted at once, you must pay the Bank 10% interest when you buy the property and if you lift the mortgage later you must pay the Bank an additional 10% interest as well as the amount of the mortgage.\n",
            "\n",
            "BANKRUPTCY\n",
            "\n",
            "You are declared bankrupt if you owe more than you can pay either to another player or to the Bank. If your debt is to another player, you must turn over to that player all that you have of value and retire from the game. In making this settlement, if you own houses or hotels, you must return these to the Bank in exchange for money to the extent of one-half the amount paid for them; this cash is given to the creditor. If you have mortgaged property you also turn this property over to your creditor but the new owner must at once pay the Bank the amount of interest on the loan, which is 10% of the value of the property. The new owner who does this may then, at his/her option, pay the principal or hold the property until some later turn, then lift the mortgage. If he/she holds property in this way until a later turn, he/she must pay the interest again upon lifting the mortgage.\n",
            "\n",
            "Should you owe the Bank, instead of another player, more than you can pay (because of taxes or penalties) even by selling off buildings and mortgaging property, you must turn over all assets to the Bank. In this case, the Bank immediately sells by auction all property so taken, except buildings. A bankrupt player must immediately retire from the game. The last player left in the game wins.\n",
            "\n",
            "MISCELLANEOUS\n",
            "\n",
            "Money can be loaned to a player only by the Bank and then only by mortgaging property. No player may borrow from or lend money to another player.\n",
            "\n",
            "We will be happy to hear your questions or comments about this game. Write to: Hasbro Games, Consumer Affairs Dept., P.O. Box 200, Pawtucket, RI 02862. Tel: 888-836-7025 (toll free). Canadian consumers please write to: Hasbro Canada Corporation, 2350 de la Province, Longueuil, QC Canada, J4G 1G2.\n",
            "\n",
            "The HASBRO, PARKER BROTHERS, and MONOPOLY names and logos, the distinctive design of the gameboard, the four corner squares, the MR. MONOPOLY name and character, and each of the distinctive elements of the board and rules are trademarks of Hasbro for its property trading game and game equipment. ©2004, 2007 Hasbro, Pawtucket, RI 02862. All Rights Reserved. TM & © denote U.S. Trademarks.\n",
            "\n",
            "PROOF OF PURCHASE\n",
            "\n",
            "Hasbro MONOPOLY\n",
            "\n",
            "monopoly.com' metadata={'source': '/content/rag-tutorial-v2/data/md/monopoly.md'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split the Documents"
      ],
      "metadata": {
        "id": "5g-GBrWbgH8z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Function"
      ],
      "metadata": {
        "id": "fNaU4JSHgT8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain.schema.document import Document\n",
        "\n",
        "def split_documents(documents: list[Document]):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=800,\n",
        "        chunk_overlap=80,\n",
        "        length_function=len,\n",
        "        is_separator_regex=False,\n",
        "    )\n",
        "    return text_splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "xS_s0T_LgO7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = load_documents()\n",
        "chunks = split_documents(documents)\n",
        "print(f\"Split {len(documents)} documents into {len(chunks)} chunks.\")\n",
        "print(chunks[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QG2r1hRLg01T",
        "outputId": "3cf74b37-0459-4b0d-e436-79e1b09586ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split 3 documents into 70 chunks.\n",
            "page_content='MONOPOLY\n",
            "\n",
            "Property Trading Game from Parker Brothers\n",
            "\n",
            "AGES 8+\n",
            "\n",
            "2 to 8 Players\n",
            "\n",
            "Contents: Gameboard, 3 dice, tokens, 32 houses, 12 hotels, Chance and Community Chest cards, Title Deed cards, play money and a Banker's tray.\n",
            "\n",
            "Now there's a faster way to play MONOPOLY. Choose to play by the classic rules for buying, renting and selling properties or use the Speed Die to get into the action faster. If you've never played the classic MONOPOLY game, refer to the Classic Rules beginning on the next page. If you already know how to play and want to use the Speed Die, just read the section below for the additional Speed Die rules.\n",
            "\n",
            "SPEED DIE RULES\n",
            "\n",
            "Learning how to Play with the Speed Die is as fast as playing with it.' metadata={'source': '/content/rag-tutorial-v2/data/md/monopoly.md'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding Function\n",
        "- https://python.langchain.com/v0.2/docs/integrations/text_embedding/\n",
        "\n",
        "\n",
        "- Create embedding for each chunk\n",
        "- Needed in 2 places\n",
        "  1. When we create database\n",
        "  2. When we query the database\n",
        "- Need to use the same embedding function"
      ],
      "metadata": {
        "id": "z93F2S6UhBki"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "DRvEITTsiI4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings.ollama import OllamaEmbeddings\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "import os"
      ],
      "metadata": {
        "id": "aKhCbzcciK0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY'] = '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'"
      ],
      "metadata": {
        "id": "eLrGD5etmxOE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Functions"
      ],
      "metadata": {
        "id": "MVgEZV--iLra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding_function():\n",
        "    \"\"\"\n",
        "    Purpose/Usage:\n",
        "    This function creates and returns an embedding function for processing text using a model.\n",
        "\n",
        "    Inputs:\n",
        "    - None\n",
        "\n",
        "    Outputs/Returns:\n",
        "    - An object that can be used to compute embeddings for text using the OpenAIEmbeddings class.\n",
        "    \"\"\"\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    return embeddings"
      ],
      "metadata": {
        "id": "GCZ23K9jhFFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Populate Database"
      ],
      "metadata": {
        "id": "6kIuUYRhjiwy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "Ou5TREick8BD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from langchain.document_loaders.pdf import PyPDFDirectoryLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain.schema.document import Document\n",
        "from langchain.vectorstores.chroma import Chroma"
      ],
      "metadata": {
        "id": "_KwHYSjuk9TL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Functions"
      ],
      "metadata": {
        "id": "KZcE7RYWlCVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_documents(reset=False):\n",
        "    \"\"\"\n",
        "    Purpose/Usage:\n",
        "    This function processes documents by optionally clearing the database, loading documents, splitting them into chunks, and adding them to a Chroma vector store.\n",
        "\n",
        "    Inputs:\n",
        "    - reset (bool): If True, the database will be cleared before processing documents.\n",
        "\n",
        "    Outputs/Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    if reset:\n",
        "        print(\"✨ Clearing Database\")\n",
        "        clear_database()\n",
        "\n",
        "    documents = load_documents()\n",
        "    chunks = split_documents(documents)\n",
        "    add_to_chroma(chunks)\n",
        "\n",
        "def split_documents(documents: list[Document]):\n",
        "    \"\"\"\n",
        "    Purpose/Usage:\n",
        "    Splits documents into smaller chunks for easier processing.\n",
        "\n",
        "    Inputs:\n",
        "    - documents (list[Document]): A list of Document objects to be split.\n",
        "\n",
        "    Outputs/Returns:\n",
        "    - A list of Document chunks.\n",
        "    \"\"\"\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=800,\n",
        "        chunk_overlap=80,\n",
        "        length_function=len,\n",
        "        is_separator_regex=False,\n",
        "    )\n",
        "    return text_splitter.split_documents(documents)\n",
        "\n",
        "def add_to_chroma(chunks: list[Document]):\n",
        "    \"\"\"\n",
        "    Purpose/Usage:\n",
        "    Adds document chunks to a Chroma vector store, updating the store with new documents.\n",
        "\n",
        "    Inputs:\n",
        "    - chunks (list[Document]): A list of Document chunks to be added to the vector store.\n",
        "\n",
        "    Outputs/Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    db = Chroma(\n",
        "        persist_directory=CHROMA_PATH, embedding_function=get_embedding_function()\n",
        "    )\n",
        "\n",
        "    chunks_with_ids = calculate_chunk_ids(chunks)\n",
        "\n",
        "    # Go through all items in the database, and get their chunk id\n",
        "    existing_items = db.get(include=[])  # IDs are always included by default\n",
        "    existing_ids = set(existing_items[\"ids\"])\n",
        "    print(f\"Number of existing documents in DB: {len(existing_ids)}\")\n",
        "\n",
        "    # Only add chunk with id that doesn't exist in the database\n",
        "    new_chunks = []\n",
        "    for chunk in chunks_with_ids:\n",
        "        if chunk.metadata[\"id\"] not in existing_ids:\n",
        "            new_chunks.append(chunk)\n",
        "\n",
        "    if len(new_chunks):\n",
        "        print(f\"👉 Adding new documents: {len(new_chunks)}\")\n",
        "        new_chunk_ids = [chunk.metadata[\"id\"] for chunk in new_chunks]\n",
        "        db.add_documents(new_chunks, ids=new_chunk_ids)\n",
        "        db.persist()\n",
        "    else:\n",
        "        print(\"✅ No new documents to add\")\n",
        "\n",
        "def calculate_chunk_ids(chunks):\n",
        "    \"\"\"\n",
        "    Purpose/Usage:\n",
        "    Calculates unique IDs for each document chunk based on its source, page number, and chunk index.\n",
        "\n",
        "    Inputs:\n",
        "    - chunks (list[Document]): A list of Document chunks.\n",
        "\n",
        "    Outputs/Returns:\n",
        "    - A list of Document chunks with updated metadata containing unique IDs.\n",
        "    \"\"\"\n",
        "    last_page_id = None\n",
        "    current_chunk_index = 0\n",
        "\n",
        "    # Loop through all the chunks\n",
        "    for chunk in chunks:\n",
        "        # Look into their metadata\n",
        "        source = chunk.metadata.get(\"source\")\n",
        "        page = chunk.metadata.get(\"page\")\n",
        "        # Concatenate source and page to make chunk id\n",
        "        current_page_id = f\"{source}:{page}\"\n",
        "\n",
        "        if current_page_id == last_page_id:\n",
        "            current_chunk_index += 1\n",
        "        # For each new page reset the chunk index\n",
        "        else:\n",
        "            current_chunk_index = 0\n",
        "\n",
        "        chunk_id = f\"{current_page_id}:{current_chunk_index}\"\n",
        "        last_page_id = current_page_id\n",
        "\n",
        "        # Add id to the chunk metadata\n",
        "        chunk.metadata[\"id\"] = chunk_id\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def clear_database():\n",
        "    \"\"\"\n",
        "    Purpose/Usage:\n",
        "    Clears the Chroma vector store database by deleting the specified directory.\n",
        "\n",
        "    Inputs:\n",
        "    - None\n",
        "\n",
        "    Outputs/Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    if os.path.exists(CHROMA_PATH):\n",
        "        shutil.rmtree(CHROMA_PATH)"
      ],
      "metadata": {
        "id": "kHNDtdlRlDjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "process_documents(reset=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71tl51Rejlea",
        "outputId": "695aebb2-a7ab-4ea9-fef2-00bcdb8f79fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✨ Clearing Database\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:151: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of existing documents in DB: 0\n",
            "👉 Adding new documents: 70\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:151: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/chroma.zip {CHROMA_PATH} -x \"*content*\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnVTUpnbwSlr",
        "outputId": "872719c4-6e64-46e5-c8f2-39bd3f491f80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: chroma/ (stored 0%)\n",
            "  adding: chroma/chroma.sqlite3 (deflated 49%)\n",
            "  adding: chroma/ab2f6e4b-174a-4076-8703-866946677948/ (stored 0%)\n",
            "  adding: chroma/ab2f6e4b-174a-4076-8703-866946677948/data_level0.bin (deflated 100%)\n",
            "  adding: chroma/ab2f6e4b-174a-4076-8703-866946677948/link_lists.bin (stored 0%)\n",
            "  adding: chroma/ab2f6e4b-174a-4076-8703-866946677948/header.bin (deflated 61%)\n",
            "  adding: chroma/ab2f6e4b-174a-4076-8703-866946677948/length.bin (deflated 35%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/chroma.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "xy3r7PviwUHi",
        "outputId": "74134aa8-4e97-42c1-f9ac-34202d4b66c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d9c25564-677b-4d25-9498-fea93b9eed19\", \"chroma.zip\", 556333)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Query ChromaDB Vector Database"
      ],
      "metadata": {
        "id": "WJ_jeU7sojnC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "OOKjJxgbpRIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores.chroma import Chroma\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain_community.llms.ollama import Ollama\n",
        "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
        "from IPython.display import display, Markdown"
      ],
      "metadata": {
        "id": "6ZzrsXNtpSQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Prompt Template"
      ],
      "metadata": {
        "id": "e9HwJ9cypTNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PROMPT_TEMPLATE = \"\"\"\n",
        "Answer the question based only on the following context:\n",
        "\n",
        "{context}\n",
        "\n",
        "---\n",
        "\n",
        "Answer the question based on the above context: {question}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "hpk_mN3mpc7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEFAULT_MODEL = 'gpt-3.5-turbo'\n",
        "def process_query_gpt_base(query_text: str, _model_name=DEFAULT_MODEL):\n",
        "    \"\"\"\n",
        "    Purpose/Usage:\n",
        "    This function processes a query by searching a database for relevant context and generating a response using a language model.\n",
        "\n",
        "    Inputs:\n",
        "    - query_text (str): The text of the query to be processed.\n",
        "\n",
        "    Outputs/Returns:\n",
        "    - response_text (str): The response generated by the language model based on the query and context.\n",
        "    \"\"\"\n",
        "    embedding_function = get_embedding_function()\n",
        "    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n",
        "\n",
        "    results = db.similarity_search_with_score(query_text, k=5)\n",
        "\n",
        "    context_text = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _score in results])\n",
        "    prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
        "    prompt = prompt_template.format(context=context_text, question=query_text)\n",
        "\n",
        "    model = ChatOpenAI(model_name=_model_name)\n",
        "    response_text = model.invoke(prompt)\n",
        "\n",
        "    sources = [doc.metadata.get(\"id\", None) for doc, _score in results]\n",
        "    formatted_response = f\"Response: {response_text}\\nSources: {sources}\"\n",
        "    print(formatted_response)\n",
        "    return response_text"
      ],
      "metadata": {
        "id": "OxKV14eIodtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_query_gpt_str(query_text: str, _model_name=DEFAULT_MODEL):\n",
        "    \"\"\"\n",
        "    Purpose/Usage:\n",
        "    This function processes a query by searching a database for relevant context and generating a response using a language model.\n",
        "\n",
        "    Inputs:\n",
        "    - query_text (str): The text of the query to be processed.\n",
        "\n",
        "    Outputs/Returns:\n",
        "    - response_text (str): The response generated by the language model based on the query and context.\n",
        "    \"\"\"\n",
        "    embedding_function = get_embedding_function()\n",
        "    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n",
        "\n",
        "    results = db.similarity_search_with_score(query_text, k=5)\n",
        "\n",
        "    # Prepare the context text with ID and relevance score for each chunk\n",
        "    context_text = \"\"\n",
        "    sources = []\n",
        "    for doc, score in results:\n",
        "        chunk_id = doc.metadata.get(\"id\", \"Unknown ID\")\n",
        "        sources.append(chunk_id)\n",
        "        context_text += f\"Chunk ID: {chunk_id}\\nRelevance Score: {score:.4f}\\nContent:\\n{doc.page_content}\\n\\n---\\n\\n\"\n",
        "\n",
        "    prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
        "    prompt = prompt_template.format(context=context_text, question=query_text)\n",
        "\n",
        "    model = ChatOpenAI(model_name=_model_name)\n",
        "    response_text = model.invoke(prompt)\n",
        "\n",
        "    formatted_response = (\n",
        "        f\"Response: {response_text}\\n\"\n",
        "        f\"Sources: {sources}\\n\"\n",
        "        f\"Chunks used:\\n{context_text}\"\n",
        "    )\n",
        "    print(formatted_response)\n",
        "    return formatted_response"
      ],
      "metadata": {
        "id": "i6WpJsJGpqTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_query_gpt_md(query_text: str, _model_name=DEFAULT_MODEL):\n",
        "    \"\"\"\n",
        "    Purpose/Usage:\n",
        "    This function processes a query by searching a database for relevant context and generating a response using a language model.\n",
        "\n",
        "    Inputs:\n",
        "    - query_text (str): The text of the query to be processed.\n",
        "\n",
        "    Outputs/Returns:\n",
        "    - None (displays the response as Markdown)\n",
        "    \"\"\"\n",
        "    embedding_function = get_embedding_function()\n",
        "    db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embedding_function)\n",
        "\n",
        "    results = db.similarity_search_with_score(query_text, k=5)\n",
        "\n",
        "    # Prepare the context text with ID, relevance score, and content formatted in Markdown\n",
        "    context_text = \"\"\n",
        "    sources = []\n",
        "    for i, (doc, score) in enumerate(results):\n",
        "        chunk_id = doc.metadata.get(\"id\", \"Unknown ID\")\n",
        "        sources.append(chunk_id)\n",
        "        context_text += f\"### Chunk {i+1} - ID: {chunk_id}\\n\"\n",
        "        context_text += f\"**Relevance Score:** {score:.4f}\\n\\n\"\n",
        "        context_text += f\"**Content:**\\n```\\n{doc.page_content}\\n```\\n\\n---\\n\\n\"\n",
        "\n",
        "    prompt_template = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
        "    prompt = prompt_template.format(context=context_text, question=query_text)\n",
        "\n",
        "    model = ChatOpenAI(model_name=_model_name)\n",
        "    response = model.invoke(prompt)\n",
        "\n",
        "    # Extract response metadata\n",
        "    response_metadata = response.response_metadata\n",
        "    usage_metadata = response.usage_metadata\n",
        "\n",
        "    # Format the response as Markdown\n",
        "    markdown_response = (\n",
        "        f\"## Response\\n\"\n",
        "        f\"{response.content}\\n\\n\"\n",
        "        f\"## Sources\\n\"\n",
        "        + \"\\n\".join(f\"- {source}\" for source in sources if source) + \"\\n\\n\"\n",
        "        f\"## Chunks Used\\n\\n\"\n",
        "        f\"{context_text}\"\n",
        "        f\"## Response Metadata\\n\"\n",
        "        f\"- **Token Usage:**\\n\"\n",
        "        f\"  - Completion Tokens: {response_metadata['token_usage']['completion_tokens']}\\n\"\n",
        "        f\"  - Prompt Tokens: {response_metadata['token_usage']['prompt_tokens']}\\n\"\n",
        "        f\"  - Total Tokens: {response_metadata['token_usage']['total_tokens']}\\n\"\n",
        "        f\"- **Model Name:** {response_metadata['model_name']}\\n\"\n",
        "        f\"- **System Fingerprint:** {response_metadata.get('system_fingerprint', 'None')}\\n\"\n",
        "        f\"- **Finish Reason:** {response_metadata['finish_reason']}\\n\"\n",
        "        f\"- **Logprobs:** {response_metadata.get('logprobs', 'None')}\\n\"\n",
        "        f\"## ID\\n\"\n",
        "        f\"- **Run ID:** {response.id}\\n\"\n",
        "        f\"## Usage Metadata\\n\"\n",
        "        f\"- **Input Tokens:** {usage_metadata['input_tokens']}\\n\"\n",
        "        f\"- **Output Tokens:** {usage_metadata['output_tokens']}\\n\"\n",
        "        f\"- **Total Tokens:** {usage_metadata['total_tokens']}\\n\"\n",
        "    )\n",
        "\n",
        "    # Display the response as Markdown\n",
        "    display(Markdown(markdown_response))"
      ],
      "metadata": {
        "id": "x3PCSWW0k3_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example Usage"
      ],
      "metadata": {
        "id": "-t_bNksuYhcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_text = \"How many clues can I give in Codenames?\"\n",
        "response = process_query_gpt_md(query_text, _model_name=\"gpt-4o-mini\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hPQA-syeYbLr",
        "outputId": "8ebba975-5b3a-4f6b-b383-805e95603011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Response\nIn Codenames, you can give a clue that relates to multiple words, but each clue must be only one word. You can suggest a clue for just one word, but it's common to try for two or more words, with a maximum of four words being a big accomplishment.\n\n## Sources\n- /content/rag-tutorial-v2/data/md/codenames-rules-en.md:None:5\n- /content/rag-tutorial-v2/data/md/codenames-rules-en.md:None:4\n- /content/rag-tutorial-v2/data/md/codenames-rules-en.md:None:11\n- /content/rag-tutorial-v2/data/md/codenames-rules-en.md:None:6\n- /content/rag-tutorial-v2/data/md/codenames-rules-en.md:None:7\n\n## Chunks Used\n\n### Chunk 1 - ID: /content/rag-tutorial-v2/data/md/codenames-rules-en.md:None:5\n**Relevance Score:** 0.2442\n\n**Content:**\n```\nGAME PLAY\n\nGIVING A CLUE\n\nIf you are the spymaster, you are trying to think of a one-word clue that relates to some of the words your team is trying to guess. When you think you have a good clue, you say it. You also say one number, which tells your teammates how many codenames are related to your clue.\n\nExample: Two of your words are NUT and BARK. Both of these grow on trees, so you say tree: 2.\n\nYou are allowed to give a clue for only one word (cashew: 1) but it's fun to try for two or more. Getting four words with one clue is a big accomplishment.\n\nOne Word\n\nYour clue must be only one word. You are not allowed to give extra hints. For example, don't say, \"This may be a bit of a stretch…\" You are playing Codenames. It's always a bit of a stretch.\n```\n\n---\n\n### Chunk 2 - ID: /content/rag-tutorial-v2/data/md/codenames-rules-en.md:None:4\n**Relevance Score:** 0.2658\n\n**Content:**\n```\nSpymasters know the secret identities of 25 agents. Their teammates know the agents only by their codenames.\n\nGAME OVERVIEW\n\nSpymasters take turns giving one-word clues. A clue may relate to multiple words on the table. The field operatives try to guess which words their spymaster meant. When a field operative touches a word, the spymaster reveals its secret identity. If the field operatives guess correctly, they may continue guessing, until they run out of ideas for the given clue or until they hit a wrong person. Then it is the other team's turn to give a clue and guess. The first team to contact all their agents wins the game.\n\nTeams take turns\n\nThe starting team is indicated by the 4 lights on the edges of the key card.\n\nGAME PLAY\n\nGIVING A CLUE\n```\n\n---\n\n### Chunk 3 - ID: /content/rag-tutorial-v2/data/md/codenames-rules-en.md:None:11\n**Relevance Score:** 0.2922\n\n**Content:**\n```\nGAME FLOW\n\nSpymasters take turns giving clues. After a spymaster gives a clue, his or her team starts guessing. Their turn ends when they guess wrong, when they decide to stop, or when they have made the maximum number of guesses for that clue. Then it is the other team's turn.\n\nENDING THE GAME\n\nThe game ends when one team has all their words covered. That team wins. It is possible to win on the other team's turn if they guess your last word. The game can end early if a field operative makes contact with the assassin. That operative's team loses.\n\nSetup for the Next Game\n\nDo other people want a chance to be spymasters? Setup for the second game is easy. Remove the cards covering the codenames and put them back in their stacks. Now just flip over the 25 codenames, and you're ready to go!\n```\n\n---\n\n### Chunk 4 - ID: /content/rag-tutorial-v2/data/md/codenames-rules-en.md:None:6\n**Relevance Score:** 0.2956\n\n**Content:**\n```\nYour clue cannot be any of the codenames visible on the table. On later turns, some codenames will be covered up, so a clue that is not legal now might be legal later.\n\nMAKING CONTACT\n\nWhen the spymaster gives a clue, his or her field operatives try to figure out what it means. They can debate it amongst themselves, but the spymaster must keep a straight face. The operatives indicate their official guess when one of them touches one of the codenames on the table.\n\nIf the field operative touches a card belonging to his or her team, the spymaster covers the word with an agent card in that color. The operatives get another guess (but not another clue).\n\nIf the field operative touches an innocent bystander, the spymaster covers it with an innocent bystander card. This ends the turn.\n```\n\n---\n\n### Chunk 5 - ID: /content/rag-tutorial-v2/data/md/codenames-rules-en.md:None:7\n**Relevance Score:** 0.3132\n\n**Content:**\n```\nIf the field operative touches a card belonging to the other team, the word is covered by one of the other team's agent cards. This ends the turn. (And it helps the other team.)\n\nIf the field operative touches the assassin, the word is covered by the assassin card. This ends the game! The team that contacted the assassin loses.\n\nTip: Before saying your clue out loud, make sure it doesn't relate to the assassin.\n\nNumber of Guesses\n\nThe field operatives must always make at least one guess. Any wrong guess ends the turn immediately, but if the field operatives guess a word of their team's color, they can keep guessing.\n\nYou can stop guessing at any time, but usually you want to guess as many words as the spymaster said. Sometimes you might even want to guess one more:\n```\n\n---\n\n## Response Metadata\n- **Token Usage:**\n  - Completion Tokens: 57\n  - Prompt Tokens: 1171\n  - Total Tokens: 1228\n- **Model Name:** gpt-4o-mini\n- **System Fingerprint:** fp_48196bc67a\n- **Finish Reason:** stop\n- **Logprobs:** None\n## ID\n- **Run ID:** run-febe1fc1-cf60-4236-ad55-6c9bc134e899-0\n## Usage Metadata\n- **Input Tokens:** 1171\n- **Output Tokens:** 57\n- **Total Tokens:** 1228\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_text = \"How do I get out of jail in Monopoly?\"\n",
        "response = process_query_gpt_md(query_text, _model_name=\"gpt-4o-mini\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZwnsKrcQYiwC",
        "outputId": "a384d42e-19c1-4efc-b9aa-fad73eb7aa11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Response\nYou can get out of jail in Monopoly by:\n\n1. Throwing doubles on any of your next three turns. If successful, you move forward the number of spaces shown by your doubles throw, but you do not take another turn.\n2. Using a \"Get Out of Jail Free\" card if you have it.\n3. Purchasing a \"Get Out of Jail Free\" card from another player and playing it.\n4. Paying a fine of $50 before you roll the dice on either of your next two turns. If you do not throw doubles by your third turn, you must pay the $50 fine to get out of jail and then move forward the number of spaces shown by your throw. \n\nWhile in jail, you can still buy and sell property, buy and sell houses and hotels, and collect rents.\n\n## Sources\n- /content/rag-tutorial-v2/data/md/monopoly.md:None:14\n- /content/rag-tutorial-v2/data/md/monopoly.md:None:12\n- /content/rag-tutorial-v2/data/md/monopoly.md:None:3\n- /content/rag-tutorial-v2/data/md/monopoly.md:None:2\n- /content/rag-tutorial-v2/data/md/monopoly.md:None:13\n\n## Chunks Used\n\n### Chunk 1 - ID: /content/rag-tutorial-v2/data/md/monopoly.md:None:14\n**Relevance Score:** 0.2295\n\n**Content:**\n```\nYou get out of Jail by: (1) throwing doubles on any of your next three turns; if you succeed in doing this you immediately move forward the number of spaces shown by your doubles throw; even though you had thrown doubles, you do not take another turn; (2) using the \"Get Out of Jail Free\" card if you have it; (3) purchasing the \"Get Out of Jail Free\" card from another player and playing it; (4) paying a fine of $50 before you roll the dice on either of your next two turns. If you do not throw doubles by your third turn, you must pay the $50 fine. You then get out of Jail and immediately move forward the number of spaces shown by your throw. Even though you are in Jail, you may buy and sell property, buy and sell houses and hotels and collect rents.\n```\n\n---\n\n### Chunk 2 - ID: /content/rag-tutorial-v2/data/md/monopoly.md:None:12\n**Relevance Score:** 0.2635\n\n**Content:**\n```\ninstructions and return the card facedown to the bottom of the deck. The \"Get Out of Jail Free\" card is held until used and then returned to the bottom of the deck. If the player who draws it does not wish to use it, he/she may sell it, at any time, to another player at a price agreeable to both.\n\nIf you land here you have two options: You may \"INCOME TAX\" at $900 and pay the Bank, or you may pay 10% of your total worth to the Bank. Your total worth is all your cash on hand, printed prices of mortgaged and unmortgaged properties and cost price of all buildings you own. You must decide which option you will take before you add up your total worth.\n```\n\n---\n\n### Chunk 3 - ID: /content/rag-tutorial-v2/data/md/monopoly.md:None:3\n**Relevance Score:** 0.2933\n\n**Content:**\n```\nNO, there are no more properties in the bank - Advance to the next property on which you will owe another player money.\n\nA few minor details:\n\nOnly the white dice are used when determining if you rolled doubles.\n\nDo not look at the Speed Die.\n\nIf you roll a three-of-a-kind (all of the dice show the same number), you can move anywhere you want on the board!\n\nIf you get sent to jail during your move (either by landing on the \"Go to Jail\" space or by rolling doubles three times in a row) then your turn is over and you do not get to use the Speed Die for that turn.\n\nUse the white dice ONLY when rolling to get out of jail.\n\nUse the sum of all three dice when determining how much to pay on a utility. Note: The Bus and Mr. Monopoly are valued at 0.\n\nClassic Monopoly Rules\n```\n\n---\n\n### Chunk 4 - ID: /content/rag-tutorial-v2/data/md/monopoly.md:None:2\n**Relevance Score:** 0.2981\n\n**Content:**\n```\nBus:\n\nThis lets you \"get off the bus early.\" Look at the two white dice. You can move the value of one die, the other die, or the sum of both dice. So if you rolled a 1 and a 5, you can move 1 space, 5 spaces, or 6 spaces: it's your choice.\n\nMr. Monopoly:\n\nFirst, move the sum of the two white dice and resolve the space you land on (such as drawing a card, buying the property, paying rent, etc.). Then, one of two things will happen depending on whether or not there is still property in the bank.\n\nYES, there is property in the bank - Advance to the next property that the bank still holds and buy it if you wish. If you don't want to buy this property, move to the space anyway and put the property up for auction.\n```\n\n---\n\n### Chunk 5 - ID: /content/rag-tutorial-v2/data/md/monopoly.md:None:13\n**Relevance Score:** 0.3021\n\n**Content:**\n```\n\"JAIL\": You land in Jail when: (1) your token lands on the space \"Go to Jail\"; (2) you draw a card marked \"Go to Jail\"; or (3) you throw doubles three times in succession. When you are sent to Jail you cannot collect your $200 salary in that move since, regardless of where your token is on the board, you must move it directly into Jail. Your turn ends when you are sent to Jail. If you are not \"sent\" to Jail but in the ordinary course of play land on that space, you are \"Just Visiting,\" you incur no penalty, and you move ahead in the usual manner on your next turn.\n```\n\n---\n\n## Response Metadata\n- **Token Usage:**\n  - Completion Tokens: 164\n  - Prompt Tokens: 1097\n  - Total Tokens: 1261\n- **Model Name:** gpt-4o-mini\n- **System Fingerprint:** fp_48196bc67a\n- **Finish Reason:** stop\n- **Logprobs:** None\n## ID\n- **Run ID:** run-e896cf43-bcbe-4a2f-8d72-29a34c42644c-0\n## Usage Metadata\n- **Input Tokens:** 1097\n- **Output Tokens:** 164\n- **Total Tokens:** 1261\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_text = \"How many points does the longest continuous train get in Ticket to Ride?\"\n",
        "response = process_query_gpt_md(query_text, _model_name=\"gpt-4o-mini\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mr1-Cf9TYlNz",
        "outputId": "b0e201bc-cb4b-4ae1-b400-cd9c6abbc59c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Response\nThe player who has the Longest Continuous Path of routes receives a special bonus card and adds 10 points to their score.\n\n## Sources\n- /content/rag-tutorial-v2/data/md/ticket_to_ride.md:None:15\n- /content/rag-tutorial-v2/data/md/ticket_to_ride.md:None:5\n- /content/rag-tutorial-v2/data/md/ticket_to_ride.md:None:13\n- /content/rag-tutorial-v2/data/md/ticket_to_ride.md:None:1\n- /content/rag-tutorial-v2/data/md/ticket_to_ride.md:None:2\n\n## Chunks Used\n\n### Chunk 1 - ID: /content/rag-tutorial-v2/data/md/ticket_to_ride.md:None:15\n**Relevance Score:** 0.2261\n\n**Content:**\n```\nThe player who has the Longest Continuous Path of routes receives this special bonus card and adds 10 points to his score. When evaluating and comparing path lengths, only take into account continuous lines of plastic trains of the same color. A continuous path may include loops, and pass through the same city several times, but a given plastic train may never be used twice in the same continuous path. In the case of a tie for the longest path, all tied players score the 10 point bonus.\n\nThe player with the most points wins the game. If two or more players are tied for the most points, the player who has completed the most Destination Tickets wins. In the unlikely event that they are still tied, the player with the Longest Continuous Path card wins.\n\nCREDITS\n\nGame design by Alan R. Moon\n```\n\n---\n\n### Chunk 2 - ID: /content/rag-tutorial-v2/data/md/ticket_to_ride.md:None:5\n**Relevance Score:** 0.2506\n\n**Content:**\n```\nCompleting the Longest Continuous Path of routes.\n\nPoints are lost if you do not successfully complete the route given on the Destination Ticket(s) you kept.\n\nThe Game Turn\n\nThe player who is the most experienced traveler goes first. Play then proceeds clockwise around the table, each player taking one turn at a time until the game ends. On his turn, a player must perform one (and only one) of the following three actions:\n\nDraw Train Car Cards\n```\n\n---\n\n### Chunk 3 - ID: /content/rag-tutorial-v2/data/md/ticket_to_ride.md:None:13\n**Relevance Score:** 0.3036\n\n**Content:**\n```\nEach Destination Ticket includes the name of two cities on the map and a Point Value. If a player successfully completes a series of routes that connect the two cities, they will add the amount of points indicated on the Destination Ticket to their point totals at the end of the game. If they do not successfully connect the two cities, they deduct the amount of points indicated.\n\nDestination Tickets are kept secret from other players until the game's final scoring. A player may have any number of Destination Ticket cards during the game.\n\nGame End\n\nWhen one player’s stock of colored plastic trains gets down to only 0, 1 or 2 trains left at the end of his turn, each player, including that player, gets one final turn. The game then ends and players calculate their final scores.\n```\n\n---\n\n### Chunk 4 - ID: /content/rag-tutorial-v2/data/md/ticket_to_ride.md:None:1\n**Relevance Score:** 0.3058\n\n**Content:**\n```\nEach succeeding year, they met to celebrate the anniversary and pay tribute to Fogg. And each year a new expedition (always more difficult) with a new wager (always more expensive) was proposed. Now at the dawn of the century it was time for a new impossible journey. The stakes: $1 Million in a winner-takes-all competition. The objective: to see which of them could travel by rail to the most cities in North America — in just 7 days. The journey would begin immediately…\n\nTicket to Ride is a cross-country train adventure. Players compete to connect different cities by laying claim to railway routes on a map of North America.\n\nTIcRET ToRIDE DAYS QF Boardgame [olLEL For 2 - 5 players ages 8 and above 30 - 60 minutes\n\nComponents\n\n1 Board map of North American train routes\n```\n\n---\n\n### Chunk 5 - ID: /content/rag-tutorial-v2/data/md/ticket_to_ride.md:None:2\n**Relevance Score:** 0.3087\n\n**Content:**\n```\nComponents\n\n1 Board map of North American train routes\n\n240 Colored Train Cars (45 each in Blue, Red, Green, Yellow and Black, plus some extra replacement cars in each color)\n\n144 Illustrated cards:\n\n110 Train Car cards (12 each of Box, Passenger, Tanker, Reefer, Freight, Hopper, Coal, and Caboose cars, plus 14 Locomotives)\n\n1 Summary card\n\n30 Destination Ticket cards\n\n1 Longest Continuous Path Bonus card\n\n1 Promotional card for additional maps\n\n1 Days of Wonder Promotional card\n\n5 Wooden Scoring Markers (1 for each player in Blue, Red, Green, Yellow and Black)\n\n1 Rules booklet\n\n1 Days of Wonder Online access number\n\nSetting up the Game\n```\n\n---\n\n## Response Metadata\n- **Token Usage:**\n  - Completion Tokens: 25\n  - Prompt Tokens: 1024\n  - Total Tokens: 1049\n- **Model Name:** gpt-4o-mini\n- **System Fingerprint:** fp_48196bc67a\n- **Finish Reason:** stop\n- **Logprobs:** None\n## ID\n- **Run ID:** run-2ae93297-6cf2-4a28-94d0-2fcb675ec602-0\n## Usage Metadata\n- **Input Tokens:** 1024\n- **Output Tokens:** 25\n- **Total Tokens:** 1049\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_text = \"How much total money does a player start with in original Monopoly? Keep it short\"\n",
        "response = process_query_gpt_md(query_text, _model_name=\"gpt-4o-mini\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rjipQJgeYmV9",
        "outputId": "935c05a4-94a3-4e24-d4df-62b73e1414c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Response\nA player starts with a total of $1,500 in original Monopoly.\n\n## Sources\n- /content/rag-tutorial-v2/data/md/monopoly.md:None:4\n- /content/rag-tutorial-v2/data/md/monopoly.md:None:2\n- /content/rag-tutorial-v2/data/md/monopoly.md:None:0\n- /content/rag-tutorial-v2/data/md/monopoly.md:None:12\n- /content/rag-tutorial-v2/data/md/monopoly.md:None:3\n\n## Chunks Used\n\n### Chunk 1 - ID: /content/rag-tutorial-v2/data/md/monopoly.md:None:4\n**Relevance Score:** 0.2840\n\n**Content:**\n```\nClassic Monopoly Rules\n\nOBJECT: The object of the game is to become the wealthiest player through buying, renting and selling property.\n\nPREPARATION: Place the board on a table and put the Chance and Community Chest cards facedown on their allotted spaces on the board. Each player chooses one token to represent him/her while traveling around the board.\n\nEach player is given $1,500 divided as follows: andP each of $500s, $100 and $50; 6 $40; 5 each of $10, $5 and $1. All remaining money and other equipment go to the Bank. Stack the Bank's money on edge in the compartments in the plastic Banker's tray.\n```\n\n---\n\n### Chunk 2 - ID: /content/rag-tutorial-v2/data/md/monopoly.md:None:2\n**Relevance Score:** 0.3592\n\n**Content:**\n```\nBus:\n\nThis lets you \"get off the bus early.\" Look at the two white dice. You can move the value of one die, the other die, or the sum of both dice. So if you rolled a 1 and a 5, you can move 1 space, 5 spaces, or 6 spaces: it's your choice.\n\nMr. Monopoly:\n\nFirst, move the sum of the two white dice and resolve the space you land on (such as drawing a card, buying the property, paying rent, etc.). Then, one of two things will happen depending on whether or not there is still property in the bank.\n\nYES, there is property in the bank - Advance to the next property that the bank still holds and buy it if you wish. If you don't want to buy this property, move to the space anyway and put the property up for auction.\n```\n\n---\n\n### Chunk 3 - ID: /content/rag-tutorial-v2/data/md/monopoly.md:None:0\n**Relevance Score:** 0.3668\n\n**Content:**\n```\nMONOPOLY\n\nProperty Trading Game from Parker Brothers\n\nAGES 8+\n\n2 to 8 Players\n\nContents: Gameboard, 3 dice, tokens, 32 houses, 12 hotels, Chance and Community Chest cards, Title Deed cards, play money and a Banker's tray.\n\nNow there's a faster way to play MONOPOLY. Choose to play by the classic rules for buying, renting and selling properties or use the Speed Die to get into the action faster. If you've never played the classic MONOPOLY game, refer to the Classic Rules beginning on the next page. If you already know how to play and want to use the Speed Die, just read the section below for the additional Speed Die rules.\n\nSPEED DIE RULES\n\nLearning how to Play with the Speed Die is as fast as playing with it.\n```\n\n---\n\n### Chunk 4 - ID: /content/rag-tutorial-v2/data/md/monopoly.md:None:12\n**Relevance Score:** 0.3809\n\n**Content:**\n```\ninstructions and return the card facedown to the bottom of the deck. The \"Get Out of Jail Free\" card is held until used and then returned to the bottom of the deck. If the player who draws it does not wish to use it, he/she may sell it, at any time, to another player at a price agreeable to both.\n\nIf you land here you have two options: You may \"INCOME TAX\" at $900 and pay the Bank, or you may pay 10% of your total worth to the Bank. Your total worth is all your cash on hand, printed prices of mortgaged and unmortgaged properties and cost price of all buildings you own. You must decide which option you will take before you add up your total worth.\n```\n\n---\n\n### Chunk 5 - ID: /content/rag-tutorial-v2/data/md/monopoly.md:None:3\n**Relevance Score:** 0.3840\n\n**Content:**\n```\nNO, there are no more properties in the bank - Advance to the next property on which you will owe another player money.\n\nA few minor details:\n\nOnly the white dice are used when determining if you rolled doubles.\n\nDo not look at the Speed Die.\n\nIf you roll a three-of-a-kind (all of the dice show the same number), you can move anywhere you want on the board!\n\nIf you get sent to jail during your move (either by landing on the \"Go to Jail\" space or by rolling doubles three times in a row) then your turn is over and you do not get to use the Speed Die for that turn.\n\nUse the white dice ONLY when rolling to get out of jail.\n\nUse the sum of all three dice when determining how much to pay on a utility. Note: The Bus and Mr. Monopoly are valued at 0.\n\nClassic Monopoly Rules\n```\n\n---\n\n## Response Metadata\n- **Token Usage:**\n  - Completion Tokens: 15\n  - Prompt Tokens: 1099\n  - Total Tokens: 1114\n- **Model Name:** gpt-4o-mini\n- **System Fingerprint:** fp_48196bc67a\n- **Finish Reason:** stop\n- **Logprobs:** None\n## ID\n- **Run ID:** run-3227ff9a-5497-494e-90f9-fc8d4c377a9b-0\n## Usage Metadata\n- **Input Tokens:** 1099\n- **Output Tokens:** 15\n- **Total Tokens:** 1114\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unit Testing"
      ],
      "metadata": {
        "id": "tMUYUT9ZLvBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DEFAULT_OLLAMA = \"mistral\""
      ],
      "metadata": {
        "id": "WIOhyFqzYRPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Prompt Template"
      ],
      "metadata": {
        "id": "vAhGEaiLLxWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EVAL_PROMPT = \"\"\"\n",
        "Expected Response: {expected_response}\n",
        "Actual Response: {actual_response}\n",
        "---\n",
        "(Answer with 'true' or 'false') Does the actual response match the expected response?\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "sdt_iWbOLwOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Functions"
      ],
      "metadata": {
        "id": "pmkrTvugMTRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_monopoly_rules():\n",
        "    \"\"\"\n",
        "    Purpose/Usage:\n",
        "    This function tests whether the response to a Monopoly rules question matches the expected answer.\n",
        "\n",
        "    Inputs:\n",
        "    - None\n",
        "\n",
        "    Outputs/Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    assert query_and_validate(\n",
        "        question=\"How much total money does a player start with in original Monopoly? (Answer with the number only without $)\",\n",
        "        expected_response=\"1500\",\n",
        "    )\n",
        "\n",
        "def evaluate_ticket_to_ride_rules():\n",
        "    \"\"\"\n",
        "    Purpose/Usage:\n",
        "    This function tests whether the response to a Ticket to Ride rules question matches the expected answer.\n",
        "\n",
        "    Inputs:\n",
        "    - None\n",
        "\n",
        "    Outputs/Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    assert query_and_validate(\n",
        "        question=\"How many points does the longest continuous train get in Ticket to Ride? (Answer with the number only)\",\n",
        "        expected_response=\"10 points\",\n",
        "    )\n",
        "\n",
        "def query_and_validate(question: str, expected_response: str):\n",
        "    \"\"\"\n",
        "    Purpose/Usage:\n",
        "    This function queries a language model with a question and validates the response against an expected answer.\n",
        "\n",
        "    Inputs:\n",
        "    - question (str): The question to be asked.\n",
        "    - expected_response (str): The expected answer to the question.\n",
        "\n",
        "    Outputs/Returns:\n",
        "    - bool: True if the actual response matches the expected response; False otherwise.\n",
        "    \"\"\"\n",
        "    response_text = process_query_gpt_base(question, _model_name=\"gpt-4o-mini\")\n",
        "    prompt = EVAL_PROMPT.format(\n",
        "        expected_response=expected_response, actual_response=response_text\n",
        "    )\n",
        "\n",
        "    model = Ollama(model=DEFAULT_OLLAMA)\n",
        "    evaluation_results_str = model.invoke(prompt)\n",
        "    evaluation_results_str_cleaned = evaluation_results_str.strip().lower()\n",
        "\n",
        "    print(prompt)\n",
        "\n",
        "    if \"true\" in evaluation_results_str_cleaned:\n",
        "        print(\"\\033[92m\" + f\"Response: {evaluation_results_str_cleaned}\" + \"\\033[0m\")\n",
        "        return True\n",
        "    elif \"false\" in evaluation_results_str_cleaned:\n",
        "        print(\"\\033[91m\" + f\"Response: {evaluation_results_str_cleaned}\" + \"\\033[0m\")\n",
        "        return False\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            f\"Invalid evaluation result. Cannot determine if 'true' or 'false'.\"\n",
        "        )"
      ],
      "metadata": {
        "id": "evPm-qfrL2yN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_monopoly_rules()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOw5V2EbMR-M",
        "outputId": "9c96ae2f-98c3-4fe8-8afa-fea6d94bc5c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: content='1500' response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 881, 'total_tokens': 883}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_48196bc67a', 'finish_reason': 'stop', 'logprobs': None} id='run-a37da93e-9488-47d4-bd57-775c088f971e-0' usage_metadata={'input_tokens': 881, 'output_tokens': 2, 'total_tokens': 883}\n",
            "Sources: ['/content/rag-tutorial-v2/data/md/monopoly.md:None:4', '/content/rag-tutorial-v2/data/md/monopoly.md:None:2', '/content/rag-tutorial-v2/data/md/monopoly.md:None:3', '/content/rag-tutorial-v2/data/md/monopoly.md:None:0', '/content/rag-tutorial-v2/data/md/monopoly.md:None:9']\n",
            "\n",
            "Expected Response: 1500\n",
            "Actual Response: content='1500' response_metadata={'token_usage': {'completion_tokens': 2, 'prompt_tokens': 881, 'total_tokens': 883}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_48196bc67a', 'finish_reason': 'stop', 'logprobs': None} id='run-a37da93e-9488-47d4-bd57-775c088f971e-0' usage_metadata={'input_tokens': 881, 'output_tokens': 2, 'total_tokens': 883}\n",
            "---\n",
            "(Answer with 'true' or 'false') Does the actual response match the expected response?\n",
            "\n",
            "\u001b[92mResponse: true\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_ticket_to_ride_rules()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqoQ8HJgMV2V",
        "outputId": "ff7baa9b-aa40-4793-ef8e-8dc362f597df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: content='10' response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 805, 'total_tokens': 806}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_f3db212e1c', 'finish_reason': 'stop', 'logprobs': None} id='run-c311a880-cd35-411d-adc7-bdd4701a3332-0' usage_metadata={'input_tokens': 805, 'output_tokens': 1, 'total_tokens': 806}\n",
            "Sources: ['/content/rag-tutorial-v2/data/md/ticket_to_ride.md:None:15', '/content/rag-tutorial-v2/data/md/ticket_to_ride.md:None:5', '/content/rag-tutorial-v2/data/md/ticket_to_ride.md:None:13', '/content/rag-tutorial-v2/data/md/ticket_to_ride.md:None:1', '/content/rag-tutorial-v2/data/md/ticket_to_ride.md:None:4']\n",
            "\n",
            "Expected Response: 10 points\n",
            "Actual Response: content='10' response_metadata={'token_usage': {'completion_tokens': 1, 'prompt_tokens': 805, 'total_tokens': 806}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_f3db212e1c', 'finish_reason': 'stop', 'logprobs': None} id='run-c311a880-cd35-411d-adc7-bdd4701a3332-0' usage_metadata={'input_tokens': 805, 'output_tokens': 1, 'total_tokens': 806}\n",
            "---\n",
            "(Answer with 'true' or 'false') Does the actual response match the expected response?\n",
            "\n",
            "\u001b[92mResponse: true\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}